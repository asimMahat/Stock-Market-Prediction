{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6790f3-2700-4235-a625-946a7994c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 21:37:07.914686: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5bd2ec-ccec-4c4f-9e0c-0a0433f90bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date      Open      High       Low     Close  Volume  \\\n",
      "0  1962-01-02 00:00:00-05:00  1.518550  1.518550  1.501487  1.501487  407940   \n",
      "1  1962-01-03 00:00:00-05:00  1.501487  1.514612  1.501487  1.514612  305955   \n",
      "2  1962-01-04 00:00:00-05:00  1.514613  1.514613  1.498863  1.499519  274575   \n",
      "3  1962-01-05 00:00:00-05:00  1.497551  1.497551  1.467363  1.469988  384405   \n",
      "4  1962-01-08 00:00:00-05:00  1.468675  1.468675  1.430613  1.442425  572685   \n",
      "\n",
      "   Dividends  Stock Splits  \n",
      "0        0.0           0.0  \n",
      "1        0.0           0.0  \n",
      "2        0.0           0.0  \n",
      "3        0.0           0.0  \n",
      "4        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "file_path = \"ibm.csv\"\n",
    "file_cleaned_path = \"cleaned_ibm.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da232944-79b3-4941-9caa-b92a88f92b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date      Open      High       Low  Volume     Close\n",
      "0  1962-01-02 00:00:00-05:00  1.518550  1.518550  1.501487  407940  1.501487\n",
      "1  1962-01-03 00:00:00-05:00  1.501487  1.514612  1.501487  305955  1.514612\n",
      "2  1962-01-04 00:00:00-05:00  1.514613  1.514613  1.498863  274575  1.499519\n",
      "3  1962-01-05 00:00:00-05:00  1.497551  1.497551  1.467363  384405  1.469988\n",
      "4  1962-01-08 00:00:00-05:00  1.468675  1.468675  1.430613  572685  1.442425\n"
     ]
    }
   ],
   "source": [
    "data_filtered = data[[\"Date\", \"Open\", \"High\", \"Low\", \"Volume\", \"Close\"]].sort_values(by=\"Date\")\n",
    "data_cleaned = data_filtered.dropna()\n",
    "print(data_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b49303c-887c-425b-96b7-b219813f129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv(file_cleaned_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58f1b61-c36b-4399-89fd-7796062bb2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02 00:00:00-05:00</td>\n",
       "      <td>1.518550</td>\n",
       "      <td>1.518550</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>407940</td>\n",
       "      <td>1.501487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03 00:00:00-05:00</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>1.514612</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>305955</td>\n",
       "      <td>1.514612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04 00:00:00-05:00</td>\n",
       "      <td>1.514613</td>\n",
       "      <td>1.514613</td>\n",
       "      <td>1.498863</td>\n",
       "      <td>274575</td>\n",
       "      <td>1.499519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05 00:00:00-05:00</td>\n",
       "      <td>1.497551</td>\n",
       "      <td>1.497551</td>\n",
       "      <td>1.467363</td>\n",
       "      <td>384405</td>\n",
       "      <td>1.469988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08 00:00:00-05:00</td>\n",
       "      <td>1.468675</td>\n",
       "      <td>1.468675</td>\n",
       "      <td>1.430613</td>\n",
       "      <td>572685</td>\n",
       "      <td>1.442425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date      Open      High       Low  Volume     Close\n",
       "0  1962-01-02 00:00:00-05:00  1.518550  1.518550  1.501487  407940  1.501487\n",
       "1  1962-01-03 00:00:00-05:00  1.501487  1.514612  1.501487  305955  1.514612\n",
       "2  1962-01-04 00:00:00-05:00  1.514613  1.514613  1.498863  274575  1.499519\n",
       "3  1962-01-05 00:00:00-05:00  1.497551  1.497551  1.467363  384405  1.469988\n",
       "4  1962-01-08 00:00:00-05:00  1.468675  1.468675  1.430613  572685  1.442425"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_cleaned_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4ceb55-da50-4a2e-a28d-cd3337987e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-02 00:00:00-05:00</td>\n",
       "      <td>1.518550</td>\n",
       "      <td>1.518550</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>407940</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>1.514612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-03 00:00:00-05:00</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>1.514612</td>\n",
       "      <td>1.501487</td>\n",
       "      <td>305955</td>\n",
       "      <td>1.514612</td>\n",
       "      <td>1.499519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-04 00:00:00-05:00</td>\n",
       "      <td>1.514613</td>\n",
       "      <td>1.514613</td>\n",
       "      <td>1.498863</td>\n",
       "      <td>274575</td>\n",
       "      <td>1.499519</td>\n",
       "      <td>1.469988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-05 00:00:00-05:00</td>\n",
       "      <td>1.497551</td>\n",
       "      <td>1.497551</td>\n",
       "      <td>1.467363</td>\n",
       "      <td>384405</td>\n",
       "      <td>1.469988</td>\n",
       "      <td>1.442425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-08 00:00:00-05:00</td>\n",
       "      <td>1.468675</td>\n",
       "      <td>1.468675</td>\n",
       "      <td>1.430613</td>\n",
       "      <td>572685</td>\n",
       "      <td>1.442425</td>\n",
       "      <td>1.459488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date      Open      High       Low  Volume     Close  \\\n",
       "0  1962-01-02 00:00:00-05:00  1.518550  1.518550  1.501487  407940  1.501487   \n",
       "1  1962-01-03 00:00:00-05:00  1.501487  1.514612  1.501487  305955  1.514612   \n",
       "2  1962-01-04 00:00:00-05:00  1.514613  1.514613  1.498863  274575  1.499519   \n",
       "3  1962-01-05 00:00:00-05:00  1.497551  1.497551  1.467363  384405  1.469988   \n",
       "4  1962-01-08 00:00:00-05:00  1.468675  1.468675  1.430613  572685  1.442425   \n",
       "\n",
       "     Target  \n",
       "0  1.514612  \n",
       "1  1.499519  \n",
       "2  1.469988  \n",
       "3  1.442425  \n",
       "4  1.459488  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Target\"] = data[\"Close\"].shift(-1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa53409-585f-4f4c-8d33-320943551eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>2024-11-13 00:00:00-05:00</td>\n",
       "      <td>209.5</td>\n",
       "      <td>211.410004</td>\n",
       "      <td>209.070099</td>\n",
       "      <td>2186158</td>\n",
       "      <td>210.669998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date   Open        High         Low   Volume  \\\n",
       "15825  2024-11-13 00:00:00-05:00  209.5  211.410004  209.070099  2186158   \n",
       "\n",
       "            Close  Target  \n",
       "15825  210.669998     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_row = data.tail(1)\n",
    "data.drop(data.tail(1).index, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "final_data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a04a50a-199b-4b90-bb4f-8708a8c8dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      0.999714\n",
       "High      0.999765\n",
       "Low       0.999767\n",
       "Volume    0.133558\n",
       "Close     0.999812\n",
       "Target    1.000000\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting correlation\n",
    "data.iloc[:, 1:].corr()['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acf50ab-df9d-4f8f-bec8-18b265ac3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features scaling\n",
    "model_features = data.drop(\"Target\", axis=1).drop(\"Date\", axis=1)\n",
    "model_target = data[\"Target\"]\n",
    "\n",
    "model_feature_scaler = MinMaxScaler()\n",
    "model_feature_scaler.fit(model_features)\n",
    "model_scaled_features = pd.DataFrame(model_feature_scaler.transform(model_features), columns=model_features.columns.tolist())\n",
    "\n",
    "model_target_scaler = MinMaxScaler()\n",
    "model_target_scaler.fit(model_target.values.reshape(-1,1))\n",
    "model_scaled_target = pd.DataFrame(model_target_scaler.transform(model_target.values.reshape(-1,1)), columns=[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47b5bf5-6df7-483c-a236-5bfd38c91f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X_data, y_data, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        v = X_data.iloc[i:(i + time_steps)].values\n",
    "        X.append(v)\n",
    "        y.append(y_data.iloc[i + time_steps])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a100388-0b30-4b4e-8cb3-71a3fc4ac577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d068e-f678-4016-b147-35197e95f71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084b8e3-edae-42b7-a613-1dafbcbcbf35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1823b2a0-48e3-480d-903c-fdc2ee27791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 146, Batch Size = 74, Time Steps = 87, Early Stopping Patience = 12, Reduce LR Factor = 0.46, Reduce LR Patience = 9, Min LR = 0.000070\n",
      "X_train shape: (12590, 87, 5), X_test shape: (3148, 87, 5)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 21:40:19.357236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n",
      "2024-12-04 21:40:19.482394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-12-04 21:40:19.482818: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f0fd0042720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-04 21:40:19.482832: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0\n",
      "2024-12-04 21:40:19.487497: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-04 21:40:19.607030: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 7s 14ms/step - loss: 0.8095 - val_loss: 0.0071 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 0.0027 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 9.8997e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 8.5326e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 7.5168e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 7.2520e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 6.2938e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 5.8268e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 5.9474e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Validation Loss: 0.001448\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 84, Batch Size = 39, Time Steps = 79, Early Stopping Patience = 6, Reduce LR Factor = 0.27, Reduce LR Patience = 5, Min LR = 0.000008\n",
      "X_train shape: (12596, 79, 5), X_test shape: (3150, 79, 5)\n",
      "Epoch 1/10\n",
      "323/323 [==============================] - 6s 9ms/step - loss: 0.3320 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0015 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 9.8166e-04 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 8.2551e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 7.5603e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 6.8466e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 6.1961e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 5.9290e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 5.7686e-04 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 5.4499e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001196\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 202, Batch Size = 31, Time Steps = 64, Early Stopping Patience = 13, Reduce LR Factor = 0.37, Reduce LR Patience = 3, Min LR = 0.000032\n",
      "X_train shape: (12608, 64, 5), X_test shape: (3153, 64, 5)\n",
      "Epoch 1/10\n",
      "407/407 [==============================] - 7s 9ms/step - loss: 0.3927 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 0.0011 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 8.9146e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 7.5825e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 7.0429e-04 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 6.5853e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 6.1801e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 6.4913e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 5.8079e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "407/407 [==============================] - 3s 7ms/step - loss: 5.7340e-04 - val_loss: 0.0055 - lr: 0.0010\n",
      "Validation Loss: 0.001172\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 152, Batch Size = 67, Time Steps = 33, Early Stopping Patience = 18, Reduce LR Factor = 0.46, Reduce LR Patience = 8, Min LR = 0.000012\n",
      "X_train shape: (12633, 33, 5), X_test shape: (3159, 33, 5)\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 5s 9ms/step - loss: 0.7413 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0012 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 9.2871e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 8.5538e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 7.4784e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 7.3069e-04 - val_loss: 0.0060 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 6.6276e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 6.3377e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 6.0650e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Validation Loss: 0.001679\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 81, Batch Size = 30, Time Steps = 77, Early Stopping Patience = 18, Reduce LR Factor = 0.25, Reduce LR Patience = 4, Min LR = 0.000045\n",
      "X_train shape: (12598, 77, 5), X_test shape: (3150, 77, 5)\n",
      "Epoch 1/10\n",
      "420/420 [==============================] - 7s 9ms/step - loss: 0.2548 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.0013 - val_loss: 0.0080 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 9.4279e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 8.3334e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 7.2822e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 6.7906e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 6.5349e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 6.1163e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 6.6608e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 6.0329e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Validation Loss: 0.001434\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 21, Time Steps = 119, Early Stopping Patience = 16, Reduce LR Factor = 0.37, Reduce LR Patience = 9, Min LR = 0.000056\n",
      "X_train shape: (12564, 119, 5), X_test shape: (3142, 119, 5)\n",
      "Epoch 1/10\n",
      "599/599 [==============================] - 9s 10ms/step - loss: 0.2992 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 8.7927e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 7.7700e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 7.5458e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 6.7368e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 7.3670e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 6.0303e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 6.2693e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "599/599 [==============================] - 6s 9ms/step - loss: 5.9297e-04 - val_loss: 0.0068 - lr: 0.0010\n",
      "Validation Loss: 0.001260\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 174, Batch Size = 52, Time Steps = 80, Early Stopping Patience = 6, Reduce LR Factor = 0.11, Reduce LR Patience = 6, Min LR = 0.000001\n",
      "X_train shape: (12596, 80, 5), X_test shape: (3149, 80, 5)\n",
      "Epoch 1/10\n",
      "243/243 [==============================] - 6s 12ms/step - loss: 0.6151 - val_loss: 0.0069 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 0.0017 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 0.0011 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 8.6995e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 7.9931e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 6.8161e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 6.4507e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 7.0135e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 6.1662e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 5.7318e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Validation Loss: 0.001272\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 16, Time Steps = 63, Early Stopping Patience = 20, Reduce LR Factor = 0.47, Reduce LR Patience = 2, Min LR = 0.000039\n",
      "X_train shape: (12609, 63, 5), X_test shape: (3153, 63, 5)\n",
      "Epoch 1/10\n",
      "789/789 [==============================] - 8s 7ms/step - loss: 0.2275 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 0.0010 - val_loss: 0.0329 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 0.0010 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 7.3673e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 8.6304e-04 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 5.6168e-04 - val_loss: 0.0026 - lr: 4.7451e-04\n",
      "Epoch 7/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 5.5054e-04 - val_loss: 0.0028 - lr: 4.7451e-04\n",
      "Epoch 8/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 4.8625e-04 - val_loss: 0.0011 - lr: 2.2516e-04\n",
      "Epoch 9/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 4.6132e-04 - val_loss: 0.0043 - lr: 2.2516e-04\n",
      "Epoch 10/10\n",
      "789/789 [==============================] - 5s 6ms/step - loss: 4.7730e-04 - val_loss: 0.0014 - lr: 2.2516e-04\n",
      "Validation Loss: 0.001096\n",
      "New best for swarm at iteration 1: [2.56000000e+02 1.60000000e+01 6.34712401e+01 2.00000000e+01\n",
      " 4.74510311e-01 2.00000000e+00 3.93676188e-05] 0.001095850020647049\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 156, Batch Size = 33, Time Steps = 55, Early Stopping Patience = 20, Reduce LR Factor = 0.30, Reduce LR Patience = 7, Min LR = 0.000010\n",
      "X_train shape: (12616, 55, 5), X_test shape: (3154, 55, 5)\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 6s 7ms/step - loss: 0.3734 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 0.0012 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 9.4381e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 8.0919e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 7.2404e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 6.7206e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 6.2253e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 5.8815e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 5.6693e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 2s 5ms/step - loss: 5.6524e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001116\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 206, Batch Size = 35, Time Steps = 31, Early Stopping Patience = 16, Reduce LR Factor = 0.43, Reduce LR Patience = 2, Min LR = 0.000090\n",
      "X_train shape: (12635, 31, 5), X_test shape: (3159, 31, 5)\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 5s 7ms/step - loss: 0.4465 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 0.0012 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 8.4088e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 7.3700e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 6.5123e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 6.4154e-04 - val_loss: 9.8463e-04 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 6.0744e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 5.7821e-04 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 4.5615e-04 - val_loss: 0.0014 - lr: 4.3069e-04\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 2s 4ms/step - loss: 4.4638e-04 - val_loss: 0.0015 - lr: 4.3069e-04\n",
      "Validation Loss: 0.000985\n",
      "New best for swarm at iteration 1: [2.06517542e+02 3.55825256e+01 3.14317417e+01 1.67278657e+01\n",
      " 4.30694609e-01 2.99157139e+00 8.95779324e-05] 0.0009846303146332502\n",
      "Best after iteration 1: [2.06517542e+02 3.55825256e+01 3.14317417e+01 1.67278657e+01\n",
      " 4.30694609e-01 2.99157139e+00 8.95779324e-05] 0.0009846303146332502\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 16, Time Steps = 105, Early Stopping Patience = 19, Reduce LR Factor = 0.34, Reduce LR Patience = 8, Min LR = 0.000064\n",
      "X_train shape: (12576, 105, 5), X_test shape: (3144, 105, 5)\n",
      "Epoch 1/10\n",
      "786/786 [==============================] - 9s 9ms/step - loss: 0.2290 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 0.0011 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 8.4387e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 8.7250e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 7.4049e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 7.1770e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 6.8587e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 6.6874e-04 - val_loss: 0.0035 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 6.9281e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "786/786 [==============================] - 6s 8ms/step - loss: 6.0324e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Validation Loss: 0.001646\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 206, Batch Size = 49, Time Steps = 73, Early Stopping Patience = 10, Reduce LR Factor = 0.10, Reduce LR Patience = 5, Min LR = 0.000001\n",
      "X_train shape: (12601, 73, 5), X_test shape: (3151, 73, 5)\n",
      "Epoch 1/10\n",
      "258/258 [==============================] - 6s 11ms/step - loss: 0.6260 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 0.0015 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 9.3368e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 9.0525e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 7.2425e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 6.4522e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 6.0916e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 4.9949e-04 - val_loss: 0.0011 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 4.7743e-04 - val_loss: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "258/258 [==============================] - 2s 8ms/step - loss: 4.7976e-04 - val_loss: 0.0012 - lr: 1.0000e-04\n",
      "Validation Loss: 0.001091\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 16, Time Steps = 57, Early Stopping Patience = 20, Reduce LR Factor = 0.50, Reduce LR Patience = 2, Min LR = 0.000055\n",
      "X_train shape: (12614, 57, 5), X_test shape: (3154, 57, 5)\n",
      "Epoch 1/10\n",
      "789/789 [==============================] - 8s 6ms/step - loss: 0.2267 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 9.9651e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 8.7040e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 7.5635e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 7.8128e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 5.3250e-04 - val_loss: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 5.3097e-04 - val_loss: 0.0016 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 5.0533e-04 - val_loss: 0.0010 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 5.4857e-04 - val_loss: 0.0021 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "789/789 [==============================] - 4s 6ms/step - loss: 4.8986e-04 - val_loss: 0.0013 - lr: 5.0000e-04\n",
      "Validation Loss: 0.001042\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 172, Batch Size = 17, Time Steps = 54, Early Stopping Patience = 20, Reduce LR Factor = 0.28, Reduce LR Patience = 4, Min LR = 0.000040\n",
      "X_train shape: (12616, 54, 5), X_test shape: (3155, 54, 5)\n",
      "Epoch 1/10\n",
      "743/743 [==============================] - 8s 6ms/step - loss: 0.2013 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 8.5838e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 7.4252e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 7.9021e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 7.1067e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 6.7271e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 6.6492e-04 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 6.2687e-04 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "743/743 [==============================] - 4s 5ms/step - loss: 6.4274e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Validation Loss: 0.001281\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 37, Time Steps = 30, Early Stopping Patience = 15, Reduce LR Factor = 0.50, Reduce LR Patience = 2, Min LR = 0.000100\n",
      "X_train shape: (12636, 30, 5), X_test shape: (3159, 30, 5)\n",
      "Epoch 1/10\n",
      "342/342 [==============================] - 5s 6ms/step - loss: 0.5226 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.0012 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 8.9379e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 7.4085e-04 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 6.2093e-04 - val_loss: 0.0035 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 6.1029e-04 - val_loss: 0.0024 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.3352e-04 - val_loss: 0.0017 - lr: 2.5000e-04\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.2035e-04 - val_loss: 0.0011 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.0993e-04 - val_loss: 0.0031 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 4.9650e-04 - val_loss: 0.0014 - lr: 2.5000e-04\n",
      "Validation Loss: 0.001134\n",
      "Best after iteration 2: [2.06517542e+02 3.55825256e+01 3.14317417e+01 1.67278657e+01\n",
      " 4.30694609e-01 2.99157139e+00 8.95779324e-05] 0.0009846303146332502\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 16, Time Steps = 92, Early Stopping Patience = 19, Reduce LR Factor = 0.34, Reduce LR Patience = 7, Min LR = 0.000069\n",
      "X_train shape: (12586, 92, 5), X_test shape: (3147, 92, 5)\n",
      "Epoch 1/10\n",
      "787/787 [==============================] - 9s 8ms/step - loss: 0.2283 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 0.0011 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 9.4865e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 7.8689e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 8.1574e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 7.8530e-04 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 7.6821e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 7.0941e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 6.6701e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "787/787 [==============================] - 6s 7ms/step - loss: 6.6011e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Validation Loss: 0.001536\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 222, Batch Size = 42, Time Steps = 61, Early Stopping Patience = 14, Reduce LR Factor = 0.21, Reduce LR Patience = 4, Min LR = 0.000035\n",
      "X_train shape: (12611, 61, 5), X_test shape: (3153, 61, 5)\n",
      "Epoch 1/10\n",
      "301/301 [==============================] - 6s 10ms/step - loss: 0.5577 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 2s 8ms/step - loss: 0.0013 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 9.1012e-04 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 7.5799e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 7.4681e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 6.2766e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 6.1918e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 5.4190e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 5.4508e-04 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 2s 7ms/step - loss: 5.6524e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001088\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 253, Batch Size = 17, Time Steps = 52, Early Stopping Patience = 20, Reduce LR Factor = 0.49, Reduce LR Patience = 2, Min LR = 0.000073\n",
      "X_train shape: (12618, 52, 5), X_test shape: (3155, 52, 5)\n",
      "Epoch 1/10\n",
      "743/743 [==============================] - 9s 8ms/step - loss: 0.2404 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 0.0010 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 8.6733e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 6.2334e-04 - val_loss: 0.0029 - lr: 4.8734e-04\n",
      "Epoch 5/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 5.9375e-04 - val_loss: 0.0100 - lr: 4.8734e-04\n",
      "Epoch 6/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 5.2173e-04 - val_loss: 0.0012 - lr: 2.3750e-04\n",
      "Epoch 7/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 4.9443e-04 - val_loss: 0.0015 - lr: 2.3750e-04\n",
      "Epoch 8/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 4.7563e-04 - val_loss: 0.0026 - lr: 2.3750e-04\n",
      "Epoch 9/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 4.3542e-04 - val_loss: 0.0017 - lr: 1.1574e-04\n",
      "Epoch 10/10\n",
      "743/743 [==============================] - 5s 6ms/step - loss: 4.2074e-04 - val_loss: 0.0015 - lr: 1.1574e-04\n",
      "Validation Loss: 0.001164\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 186, Batch Size = 20, Time Steps = 50, Early Stopping Patience = 19, Reduce LR Factor = 0.28, Reduce LR Patience = 3, Min LR = 0.000044\n",
      "X_train shape: (12620, 50, 5), X_test shape: (3155, 50, 5)\n",
      "Epoch 1/10\n",
      "631/631 [==============================] - 7s 6ms/step - loss: 0.2459 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 0.0011 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 8.8675e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 7.5627e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 7.6347e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 6.7046e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 5.0694e-04 - val_loss: 0.0034 - lr: 2.7800e-04\n",
      "Epoch 8/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 4.9285e-04 - val_loss: 0.0013 - lr: 2.7800e-04\n",
      "Epoch 9/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 4.7484e-04 - val_loss: 0.0015 - lr: 2.7800e-04\n",
      "Epoch 10/10\n",
      "631/631 [==============================] - 3s 5ms/step - loss: 4.3382e-04 - val_loss: 0.0014 - lr: 7.7282e-05\n",
      "Validation Loss: 0.001326\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 37, Time Steps = 30, Early Stopping Patience = 15, Reduce LR Factor = 0.49, Reduce LR Patience = 2, Min LR = 0.000100\n",
      "X_train shape: (12636, 30, 5), X_test shape: (3159, 30, 5)\n",
      "Epoch 1/10\n",
      "342/342 [==============================] - 5s 6ms/step - loss: 0.5244 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 0.0012 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 9.6736e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 8.0727e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 6.5328e-04 - val_loss: 0.0022 - lr: 4.9077e-04\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 6.2091e-04 - val_loss: 0.0020 - lr: 4.9077e-04\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.8189e-04 - val_loss: 0.0030 - lr: 4.9077e-04\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.7461e-04 - val_loss: 0.0010 - lr: 4.9077e-04\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.3253e-04 - val_loss: 0.0018 - lr: 4.9077e-04\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 1s 4ms/step - loss: 5.1143e-04 - val_loss: 0.0028 - lr: 4.9077e-04\n",
      "Validation Loss: 0.001022\n",
      "Best after iteration 3: [2.06517542e+02 3.55825256e+01 3.14317417e+01 1.67278657e+01\n",
      " 4.30694609e-01 2.99157139e+00 8.95779324e-05] 0.0009846303146332502\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 253, Batch Size = 24, Time Steps = 69, Early Stopping Patience = 18, Reduce LR Factor = 0.39, Reduce LR Patience = 5, Min LR = 0.000078\n",
      "X_train shape: (12604, 69, 5), X_test shape: (3152, 69, 5)\n",
      "Epoch 1/10\n",
      "526/526 [==============================] - 8s 9ms/step - loss: 0.3400 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 0.0011 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 8.5626e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 7.9515e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 7.7118e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 6.8827e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 6.1994e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 6.5358e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 6.2825e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "526/526 [==============================] - 4s 8ms/step - loss: 4.9158e-04 - val_loss: 0.0018 - lr: 3.8650e-04\n",
      "Validation Loss: 0.001285\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 229, Batch Size = 38, Time Steps = 46, Early Stopping Patience = 17, Reduce LR Factor = 0.26, Reduce LR Patience = 3, Min LR = 0.000068\n",
      "X_train shape: (12623, 46, 5), X_test shape: (3156, 46, 5)\n",
      "Epoch 1/10\n",
      "333/333 [==============================] - 6s 8ms/step - loss: 0.5085 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 0.0012 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 8.8804e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 7.7210e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 6.6253e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 6.2349e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 6.1109e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 5.3910e-04 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 5.4019e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "333/333 [==============================] - 2s 6ms/step - loss: 4.1004e-04 - val_loss: 0.0020 - lr: 2.5978e-04\n",
      "Validation Loss: 0.001003\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 239, Batch Size = 24, Time Steps = 51, Early Stopping Patience = 19, Reduce LR Factor = 0.46, Reduce LR Patience = 2, Min LR = 0.000088\n",
      "X_train shape: (12619, 51, 5), X_test shape: (3155, 51, 5)\n",
      "Epoch 1/10\n",
      "526/526 [==============================] - 7s 8ms/step - loss: 0.3287 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 0.0010 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 9.1085e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 7.2105e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 7.3450e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 5.3714e-04 - val_loss: 0.0024 - lr: 4.5947e-04\n",
      "Epoch 7/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 5.3015e-04 - val_loss: 0.0037 - lr: 4.5947e-04\n",
      "Epoch 8/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 4.5589e-04 - val_loss: 0.0038 - lr: 2.1111e-04\n",
      "Epoch 9/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 4.4847e-04 - val_loss: 0.0016 - lr: 2.1111e-04\n",
      "Epoch 10/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 4.2583e-04 - val_loss: 0.0015 - lr: 9.7001e-05\n",
      "Validation Loss: 0.001379\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 190, Batch Size = 27, Time Steps = 47, Early Stopping Patience = 18, Reduce LR Factor = 0.31, Reduce LR Patience = 4, Min LR = 0.000032\n",
      "X_train shape: (12622, 47, 5), X_test shape: (3156, 47, 5)\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 6s 7ms/step - loss: 0.3353 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 0.0011 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 8.6469e-04 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 8.1347e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 7.4713e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 6.7789e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 6.1941e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 6.5713e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 6.4372e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 3s 6ms/step - loss: 6.1827e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Validation Loss: 0.001361\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 229, Batch Size = 36, Time Steps = 30, Early Stopping Patience = 15, Reduce LR Factor = 0.45, Reduce LR Patience = 2, Min LR = 0.000099\n",
      "X_train shape: (12636, 30, 5), X_test shape: (3159, 30, 5)\n",
      "Epoch 1/10\n",
      "351/351 [==============================] - 5s 6ms/step - loss: 0.4832 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.0012 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 8.8117e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 7.0272e-04 - val_loss: 0.0012 - lr: 4.5228e-04\n",
      "Epoch 5/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 6.2894e-04 - val_loss: 0.0022 - lr: 4.5228e-04\n",
      "Epoch 6/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 5.9937e-04 - val_loss: 0.0015 - lr: 4.5228e-04\n",
      "Epoch 7/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 5.2311e-04 - val_loss: 0.0014 - lr: 2.0455e-04\n",
      "Epoch 8/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 5.2318e-04 - val_loss: 9.8446e-04 - lr: 2.0455e-04\n",
      "Epoch 9/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 5.0439e-04 - val_loss: 0.0018 - lr: 2.0455e-04\n",
      "Epoch 10/10\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 4.9038e-04 - val_loss: 0.0014 - lr: 2.0455e-04\n",
      "Validation Loss: 0.000984\n",
      "New best for swarm at iteration 4: [2.29115555e+02 3.65869809e+01 3.00000000e+01 1.57527053e+01\n",
      " 4.52276978e-01 2.85053659e+00 9.92485068e-05] 0.0009844627929851413\n",
      "Best after iteration 4: [2.29115555e+02 3.65869809e+01 3.00000000e+01 1.57527053e+01\n",
      " 4.52276978e-01 2.85053659e+00 9.92485068e-05] 0.0009844627929851413\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 242, Batch Size = 33, Time Steps = 44, Early Stopping Patience = 16, Reduce LR Factor = 0.41, Reduce LR Patience = 4, Min LR = 0.000083\n",
      "X_train shape: (12624, 44, 5), X_test shape: (3157, 44, 5)\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 6s 8ms/step - loss: 0.4549 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 0.0012 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 8.8196e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 7.5395e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 6.7844e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 7.1382e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 6.1336e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 6.0003e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 6.0853e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 2s 6ms/step - loss: 5.3829e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Validation Loss: 0.001174\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 232, Batch Size = 36, Time Steps = 34, Early Stopping Patience = 18, Reduce LR Factor = 0.35, Reduce LR Patience = 3, Min LR = 0.000095\n",
      "X_train shape: (12632, 34, 5), X_test shape: (3159, 34, 5)\n",
      "Epoch 1/10\n",
      "351/351 [==============================] - 5s 6ms/step - loss: 0.4844 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.0012 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 8.8766e-04 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 7.7214e-04 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 6.3687e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 5.3703e-04 - val_loss: 0.0020 - lr: 3.5250e-04\n",
      "Epoch 7/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 5.0734e-04 - val_loss: 0.0012 - lr: 3.5250e-04\n",
      "Epoch 8/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 5.0823e-04 - val_loss: 0.0014 - lr: 3.5250e-04\n",
      "Epoch 9/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 4.8579e-04 - val_loss: 0.0019 - lr: 3.5250e-04\n",
      "Epoch 10/10\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 4.8105e-04 - val_loss: 0.0026 - lr: 3.5250e-04\n",
      "Validation Loss: 0.001161\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 234, Batch Size = 30, Time Steps = 46, Early Stopping Patience = 18, Reduce LR Factor = 0.46, Reduce LR Patience = 2, Min LR = 0.000095\n",
      "X_train shape: (12623, 46, 5), X_test shape: (3156, 46, 5)\n",
      "Epoch 1/10\n",
      "421/421 [==============================] - 6s 8ms/step - loss: 0.4073 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 0.0011 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 8.7926e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 7.4224e-04 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 6.9949e-04 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 5.6003e-04 - val_loss: 0.0017 - lr: 4.6194e-04\n",
      "Epoch 7/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 5.2947e-04 - val_loss: 0.0049 - lr: 4.6194e-04\n",
      "Epoch 8/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 4.7649e-04 - val_loss: 0.0018 - lr: 2.1339e-04\n",
      "Epoch 9/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 4.4513e-04 - val_loss: 0.0032 - lr: 2.1339e-04\n",
      "Epoch 10/10\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 4.3610e-04 - val_loss: 0.0012 - lr: 9.8574e-05\n",
      "Validation Loss: 0.001182\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 192, Batch Size = 34, Time Steps = 41, Early Stopping Patience = 17, Reduce LR Factor = 0.33, Reduce LR Patience = 5, Min LR = 0.000040\n",
      "X_train shape: (12627, 41, 5), X_test shape: (3157, 41, 5)\n",
      "Epoch 1/10\n",
      "372/372 [==============================] - 6s 7ms/step - loss: 0.4235 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 0.0013 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 8.9245e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 7.6254e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 7.5047e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 6.7562e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 5.9287e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 6.2006e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 5.7494e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 2s 5ms/step - loss: 5.5522e-04 - val_loss: 0.0100 - lr: 0.0010\n",
      "Validation Loss: 0.001203\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 215, Batch Size = 35, Time Steps = 30, Early Stopping Patience = 15, Reduce LR Factor = 0.43, Reduce LR Patience = 3, Min LR = 0.000099\n",
      "X_train shape: (12636, 30, 5), X_test shape: (3159, 30, 5)\n",
      "Epoch 1/10\n",
      "362/362 [==============================] - 6s 7ms/step - loss: 0.4551 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 8.4409e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 7.2827e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 7.1891e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 6.5867e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 5.9351e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 5.5712e-04 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.7230e-04 - val_loss: 0.0014 - lr: 4.3303e-04\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 4.3948e-04 - val_loss: 0.0010 - lr: 4.3303e-04\n",
      "Validation Loss: 0.001026\n",
      "Best after iteration 5: [2.29115555e+02 3.65869809e+01 3.00000000e+01 1.57527053e+01\n",
      " 4.52276978e-01 2.85053659e+00 9.92485068e-05] 0.0009844627929851413\n",
      "Stopping search: maximum iterations reached --> 5\n",
      "\n",
      "Best Hyperparameters: LSTM Units = 229, Batch Size = 36, Time Steps = 30, Early Stopping Patience = 15, Reduce LR Factor = 0.45, Reduce LR Patience = 2, Min LR = 0.000099\n",
      "Best Validation Loss = 0.000984\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pyswarm\n",
    "from pyswarm import pso\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "param_ranges = {\n",
    "    \"lstm_units\": (32, 256),           # Range for LSTM units\n",
    "    \"batch_size\": (16, 128),           # Range for batch size\n",
    "    \"time_steps\": (30, 120),           # Range for sequence length\n",
    "    \"early_stopping_patience\": (5, 20),  # Range for early stopping patience\n",
    "    \"reduce_lr_factor\": (0.1, 0.5),      # Range for reduce_lr factor\n",
    "    \"reduce_lr_patience\": (2, 10),       # Range for reduce_lr patience\n",
    "    \"reduce_lr_min_lr\": (1e-6, 1e-4)     # Range for minimum learning rate\n",
    "}\n",
    "\n",
    "bounds = [\n",
    "    param_ranges[\"lstm_units\"],            # Bounds for LSTM units\n",
    "    param_ranges[\"batch_size\"],            # Bounds for batch size\n",
    "    param_ranges[\"time_steps\"],            # Bounds for sequence length\n",
    "    param_ranges[\"early_stopping_patience\"],  # Bounds for early stopping patience\n",
    "    param_ranges[\"reduce_lr_factor\"],         # Bounds for reduce_lr factor\n",
    "    param_ranges[\"reduce_lr_patience\"],       # Bounds for reduce_lr patience\n",
    "    param_ranges[\"reduce_lr_min_lr\"]          # Bounds for reduce_lr min_lr\n",
    "]\n",
    "\n",
    "def objective_function(params):\n",
    "    lstm_units = int(params[0])\n",
    "    batch_size = int(params[1])\n",
    "    time_steps = int(params[2])\n",
    "    early_stopping_patience = int(params[3])\n",
    "    reduce_lr_factor = float(params[4])\n",
    "    reduce_lr_patience = int(params[5])\n",
    "    reduce_lr_min_lr = float(params[6])\n",
    "    \n",
    "    print(f\"\\nTrying Hyperparameters: LSTM Units = {lstm_units}, Batch Size = {batch_size}, \"\n",
    "          f\"Time Steps = {time_steps}, Early Stopping Patience = {early_stopping_patience}, \"\n",
    "          f\"Reduce LR Factor = {reduce_lr_factor:.2f}, Reduce LR Patience = {reduce_lr_patience}, \"\n",
    "          f\"Min LR = {reduce_lr_min_lr:.6f}\")\n",
    "\n",
    "    # Updating sequence length for data creation\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    X, y = create_dataset(model_scaled_features, model_scaled_target, time_steps)\n",
    "    train_size = int(0.80 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Converting to tensors\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "    \n",
    "    input_shape = (time_steps, X_train.shape[2])\n",
    "    print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "\n",
    "    # Defining the new model architecture\n",
    "    model = Sequential([\n",
    "        # First LSTM layer with regularization\n",
    "        LSTM(lstm_units, return_sequences=True,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01),\n",
    "             input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Second LSTM layer\n",
    "        LSTM(lstm_units, return_sequences=False,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Output layer\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=early_stopping_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=reduce_lr_factor,\n",
    "        patience=reduce_lr_patience,\n",
    "        min_lr=reduce_lr_min_lr\n",
    "    )\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        X_train_tensor, y_train_tensor,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_tensor, y_test_tensor),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Getting validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Running PSO with the new model\n",
    "best_params, best_loss = pso(\n",
    "    objective_function,\n",
    "    lb=[b[0] for b in bounds],  # Lower bounds\n",
    "    ub=[b[1] for b in bounds],  # Upper bounds\n",
    "    swarmsize=5,               # Number of particles\n",
    "    maxiter=5,                 # Number of iterations\n",
    "    debug=True                  # Enable logging\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: LSTM Units = {int(best_params[0])}, Batch Size = {int(best_params[1])}, \"\n",
    "      f\"Time Steps = {int(best_params[2])}, Early Stopping Patience = {int(best_params[3])}, \"\n",
    "      f\"Reduce LR Factor = {best_params[4]:.2f}, Reduce LR Patience = {int(best_params[5])}, \"\n",
    "      f\"Min LR = {best_params[6]:.6f}\")\n",
    "print(f\"Best Validation Loss = {best_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04cd66-acad-481d-a651-958a1d217626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "016be382-5aa3-4fc3-a1c2-31da2a0d9139",
   "metadata": {},
   "source": [
    "## PSO 6, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40517352-82f4-4c7d-8c7f-15c6026cb832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6387bf-1251-4780-beab-c17abf8f50fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac8eb79-7059-4f39-84e2-8232b2ad4c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 254, Batch Size = 28, Time Steps = 113, Early Stopping Patience = 19, Reduce LR Factor = 0.11, Reduce LR Patience = 5, Min LR = 0.000065\n",
      "X_train shape: (12569, 113, 5), X_test shape: (3143, 113, 5)\n",
      "Epoch 1/10\n",
      "449/449 [==============================] - 9s 13ms/step - loss: 0.3975 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 0.0011 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 8.5507e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 7.9769e-04 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 7.0095e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 6.2897e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 6.2139e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 6.1631e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 7.2098e-04 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - 5s 12ms/step - loss: 6.3588e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Validation Loss: 0.001182\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 148, Batch Size = 109, Time Steps = 115, Early Stopping Patience = 19, Reduce LR Factor = 0.19, Reduce LR Patience = 3, Min LR = 0.000050\n",
      "X_train shape: (12568, 115, 5), X_test shape: (3142, 115, 5)\n",
      "Epoch 1/10\n",
      "116/116 [==============================] - 5s 19ms/step - loss: 1.1934 - val_loss: 0.0439 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.0105 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.0021 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 8.5940e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 7.7276e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 7.5526e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 6.6109e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "116/116 [==============================] - 1s 11ms/step - loss: 6.0351e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Validation Loss: 0.001436\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 225, Batch Size = 91, Time Steps = 55, Early Stopping Patience = 9, Reduce LR Factor = 0.18, Reduce LR Patience = 3, Min LR = 0.000030\n",
      "X_train shape: (12616, 55, 5), X_test shape: (3154, 55, 5)\n",
      "Epoch 1/10\n",
      "139/139 [==============================] - 5s 15ms/step - loss: 1.2075 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - 1s 9ms/step - loss: 8.6374e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - 1s 9ms/step - loss: 7.6855e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 7.1521e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 6.5505e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - 1s 9ms/step - loss: 6.1859e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - 1s 8ms/step - loss: 5.1815e-04 - val_loss: 0.0014 - lr: 1.7688e-04\n",
      "Validation Loss: 0.001417\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 101, Batch Size = 74, Time Steps = 102, Early Stopping Patience = 7, Reduce LR Factor = 0.26, Reduce LR Patience = 2, Min LR = 0.000021\n",
      "X_train shape: (12578, 102, 5), X_test shape: (3145, 102, 5)\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 5s 14ms/step - loss: 0.6885 - val_loss: 0.0156 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 0.0042 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 9.1956e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 8.3828e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 7.8000e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 7.0372e-04 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 6.2252e-04 - val_loss: 0.0025 - lr: 2.6382e-04\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 6.1085e-04 - val_loss: 0.0020 - lr: 2.6382e-04\n",
      "Validation Loss: 0.002032\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 73, Batch Size = 86, Time Steps = 72, Early Stopping Patience = 14, Reduce LR Factor = 0.13, Reduce LR Patience = 2, Min LR = 0.000066\n",
      "X_train shape: (12602, 72, 5), X_test shape: (3151, 72, 5)\n",
      "Epoch 1/10\n",
      "147/147 [==============================] - 5s 12ms/step - loss: 0.6866 - val_loss: 0.0466 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0119 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0020 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 8.5884e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 7.5359e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 6.7957e-04 - val_loss: 0.0027 - lr: 1.2895e-04\n",
      "Epoch 9/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 6.5957e-04 - val_loss: 0.0026 - lr: 1.2895e-04\n",
      "Epoch 10/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 6.6358e-04 - val_loss: 0.0025 - lr: 6.6407e-05\n",
      "Validation Loss: 0.002213\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 79, Batch Size = 96, Time Steps = 97, Early Stopping Patience = 18, Reduce LR Factor = 0.48, Reduce LR Patience = 4, Min LR = 0.000057\n",
      "X_train shape: (12582, 97, 5), X_test shape: (3146, 97, 5)\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 5s 15ms/step - loss: 0.7871 - val_loss: 0.0637 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0167 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 9.0404e-04 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 8.1537e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 7.4724e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 6.8341e-04 - val_loss: 0.0049 - lr: 4.8369e-04\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 6.3993e-04 - val_loss: 0.0034 - lr: 4.8369e-04\n",
      "Validation Loss: 0.001753\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 236, Batch Size = 16, Time Steps = 120, Early Stopping Patience = 18, Reduce LR Factor = 0.17, Reduce LR Patience = 5, Min LR = 0.000061\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "786/786 [==============================] - 11s 10ms/step - loss: 0.2198 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 0.0011 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 8.5882e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 8.5350e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 7.5868e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 7.1590e-04 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 7.6836e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 6.6794e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 6.6523e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "786/786 [==============================] - 7s 9ms/step - loss: 4.2247e-04 - val_loss: 0.0027 - lr: 1.6571e-04\n",
      "Validation Loss: 0.001822\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 102, Time Steps = 102, Early Stopping Patience = 12, Reduce LR Factor = 0.34, Reduce LR Patience = 4, Min LR = 0.000014\n",
      "X_train shape: (12578, 102, 5), X_test shape: (3145, 102, 5)\n",
      "Epoch 1/10\n",
      "124/124 [==============================] - 5s 16ms/step - loss: 1.4401 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 0.0039 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 9.3021e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 8.6759e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 7.6009e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 6.8003e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 6.3327e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 5.6303e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Validation Loss: 0.001265\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 243, Batch Size = 67, Time Steps = 94, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 6, Min LR = 0.000070\n",
      "X_train shape: (12584, 94, 5), X_test shape: (3147, 94, 5)\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 16ms/step - loss: 0.9274 - val_loss: 0.0073 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0021 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 9.1978e-04 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 7.7667e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 7.0300e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 6.6249e-04 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 6.3732e-04 - val_loss: 0.0035 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 5.9017e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 5.3455e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Validation Loss: 0.001119\n",
      "New best for swarm at iteration 1: [2.43986845e+02 6.79225077e+01 9.45354261e+01 9.47296342e+00\n",
      " 1.00000000e-01 6.53059311e+00 7.00594334e-05] 0.0011186618357896805\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 163, Batch Size = 73, Time Steps = 99, Early Stopping Patience = 12, Reduce LR Factor = 0.15, Reduce LR Patience = 4, Min LR = 0.000022\n",
      "X_train shape: (12580, 99, 5), X_test shape: (3146, 99, 5)\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 6s 15ms/step - loss: 0.8416 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 0.0027 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 0.0013 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 8.4843e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 7.4938e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 6.7112e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 6.4141e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 5.9746e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 5.7245e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Validation Loss: 0.001577\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 130, Batch Size = 92, Time Steps = 59, Early Stopping Patience = 16, Reduce LR Factor = 0.10, Reduce LR Patience = 3, Min LR = 0.000100\n",
      "X_train shape: (12612, 59, 5), X_test shape: (3154, 59, 5)\n",
      "Epoch 1/10\n",
      "138/138 [==============================] - 5s 13ms/step - loss: 0.9431 - val_loss: 0.0257 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.0011 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 9.3147e-04 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 8.5013e-04 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 8.1335e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 7.0453e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 6.7955e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 6.2364e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Validation Loss: 0.001657\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 32, Batch Size = 84, Time Steps = 120, Early Stopping Patience = 19, Reduce LR Factor = 0.50, Reduce LR Patience = 8, Min LR = 0.000028\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 5s 14ms/step - loss: 0.4575 - val_loss: 0.0964 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0318 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0016 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 9.5910e-04 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.7608e-04 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.3556e-04 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.0836e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Validation Loss: 0.003270\n",
      "Best after iteration 1: [2.43986845e+02 6.79225077e+01 9.45354261e+01 9.47296342e+00\n",
      " 1.00000000e-01 6.53059311e+00 7.00594334e-05] 0.0011186618357896805\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 235, Batch Size = 22, Time Steps = 120, Early Stopping Patience = 16, Reduce LR Factor = 0.18, Reduce LR Patience = 5, Min LR = 0.000065\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "572/572 [==============================] - 11s 14ms/step - loss: 0.3017 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 0.0011 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 9.2783e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 7.9346e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 7.9731e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 7.5138e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 7.5727e-04 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 6.5423e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 6.3697e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "572/572 [==============================] - 7s 12ms/step - loss: 6.7499e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Validation Loss: 0.001593\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 94, Time Steps = 93, Early Stopping Patience = 8, Reduce LR Factor = 0.34, Reduce LR Patience = 5, Min LR = 0.000014\n",
      "X_train shape: (12585, 93, 5), X_test shape: (3147, 93, 5)\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 5s 15ms/step - loss: 1.3308 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0033 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 9.2273e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 8.3939e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 7.3901e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 7.1419e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 6.3542e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 1s 10ms/step - loss: 5.8725e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Validation Loss: 0.001364\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 253, Batch Size = 55, Time Steps = 113, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 8, Min LR = 0.000090\n",
      "X_train shape: (12569, 113, 5), X_test shape: (3143, 113, 5)\n",
      "Epoch 1/10\n",
      "229/229 [==============================] - 7s 16ms/step - loss: 0.7748 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 0.0016 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 9.5545e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 7.9744e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 6.8540e-04 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 7.0765e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 6.6257e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 5.8023e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 5.9574e-04 - val_loss: 9.9188e-04 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "229/229 [==============================] - 3s 13ms/step - loss: 5.2748e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Validation Loss: 0.000992\n",
      "New best for swarm at iteration 2: [2.53358441e+02 5.59592897e+01 1.13959244e+02 9.42132685e+00\n",
      " 1.00000000e-01 8.09079482e+00 9.02701223e-05] 0.0009918790310621262\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 218, Batch Size = 66, Time Steps = 102, Early Stopping Patience = 13, Reduce LR Factor = 0.10, Reduce LR Patience = 6, Min LR = 0.000036\n",
      "X_train shape: (12578, 102, 5), X_test shape: (3145, 102, 5)\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 6s 18ms/step - loss: 0.8687 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.0019 - val_loss: 0.0069 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.0011 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 8.8255e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 7.6829e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 6.8621e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 6.4699e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 6.5100e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 5.7426e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 5.4484e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Validation Loss: 0.001024\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 208, Batch Size = 94, Time Steps = 54, Early Stopping Patience = 15, Reduce LR Factor = 0.10, Reduce LR Patience = 3, Min LR = 0.000100\n",
      "X_train shape: (12616, 54, 5), X_test shape: (3155, 54, 5)\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 5s 11ms/step - loss: 1.2006 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 8.8694e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 7.4618e-04 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 6.7902e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 6.1154e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 5.6629e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 5.9729e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Validation Loss: 0.001104\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 34, Batch Size = 76, Time Steps = 120, Early Stopping Patience = 17, Reduce LR Factor = 0.44, Reduce LR Patience = 9, Min LR = 0.000045\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 5s 14ms/step - loss: 0.4293 - val_loss: 0.0655 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 0.0200 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 0.0025 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 0.0014 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 9.8050e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 8.9105e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 7.9853e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 7.3946e-04 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 7.1095e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Validation Loss: 0.002415\n",
      "Best after iteration 2: [2.53358441e+02 5.59592897e+01 1.13959244e+02 9.42132685e+00\n",
      " 1.00000000e-01 8.09079482e+00 9.02701223e-05] 0.0009918790310621262\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 248, Batch Size = 32, Time Steps = 119, Early Stopping Patience = 13, Reduce LR Factor = 0.15, Reduce LR Patience = 5, Min LR = 0.000079\n",
      "X_train shape: (12564, 119, 5), X_test shape: (3142, 119, 5)\n",
      "Epoch 1/10\n",
      "393/393 [==============================] - 8s 12ms/step - loss: 0.4482 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 0.0012 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 8.4381e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 7.9019e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 6.8852e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 6.1997e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 6.4771e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 5.9615e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 6.2923e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 5.4542e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Validation Loss: 0.001378\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 77, Time Steps = 95, Early Stopping Patience = 6, Reduce LR Factor = 0.28, Reduce LR Patience = 7, Min LR = 0.000041\n",
      "X_train shape: (12584, 95, 5), X_test shape: (3146, 95, 5)\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 5s 14ms/step - loss: 1.0887 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 0.0024 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 9.4483e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 8.0142e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 7.0779e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 7.6001e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 6.1387e-04 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 6.4923e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 2s 10ms/step - loss: 5.8415e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001144\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 49, Time Steps = 120, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 8, Min LR = 0.000100\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "257/257 [==============================] - 6s 13ms/step - loss: 0.6965 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 9.5732e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 8.9758e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.9390e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.5625e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.4855e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.3220e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.0514e-04 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 5.9918e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Validation Loss: 0.001002\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 59, Time Steps = 108, Early Stopping Patience = 12, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000046\n",
      "X_train shape: (12573, 108, 5), X_test shape: (3144, 108, 5)\n",
      "Epoch 1/10\n",
      "214/214 [==============================] - 6s 13ms/step - loss: 0.8359 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 8.3311e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 7.1070e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 7.0093e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 6.4899e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 6.0794e-04 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 6.3010e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 5.7858e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Validation Loss: 0.001054\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 84, Time Steps = 77, Early Stopping Patience = 12, Reduce LR Factor = 0.10, Reduce LR Patience = 4, Min LR = 0.000100\n",
      "X_train shape: (12598, 77, 5), X_test shape: (3150, 77, 5)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 5s 14ms/step - loss: 1.1846 - val_loss: 0.0060 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 9.6877e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 8.2441e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.2836e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 7.4175e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 6.5768e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 6.1866e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 5.1625e-04 - val_loss: 0.0013 - lr: 1.0000e-04\n",
      "Validation Loss: 0.001252\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 117, Batch Size = 78, Time Steps = 120, Early Stopping Patience = 15, Reduce LR Factor = 0.40, Reduce LR Patience = 7, Min LR = 0.000066\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 15ms/step - loss: 0.7701 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0041 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0014 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0010 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 8.8054e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.7078e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.3477e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.5681e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.6548e-04 - val_loss: 0.0035 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.0718e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Validation Loss: 0.001677\n",
      "Best after iteration 3: [2.53358441e+02 5.59592897e+01 1.13959244e+02 9.42132685e+00\n",
      " 1.00000000e-01 8.09079482e+00 9.02701223e-05] 0.0009918790310621262\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 44, Time Steps = 117, Early Stopping Patience = 11, Reduce LR Factor = 0.11, Reduce LR Patience = 6, Min LR = 0.000084\n",
      "X_train shape: (12566, 117, 5), X_test shape: (3142, 117, 5)\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 6s 12ms/step - loss: 0.6242 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 0.0014 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 9.6449e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 8.1544e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 7.6693e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 7.0958e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 5.9338e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 6.0823e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 5.4529e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 3s 10ms/step - loss: 6.0600e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Validation Loss: 0.001014\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 64, Time Steps = 103, Early Stopping Patience = 7, Reduce LR Factor = 0.24, Reduce LR Patience = 7, Min LR = 0.000075\n",
      "X_train shape: (12577, 103, 5), X_test shape: (3145, 103, 5)\n",
      "Epoch 1/10\n",
      "197/197 [==============================] - 6s 13ms/step - loss: 0.9072 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 0.0020 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 9.3548e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 8.1046e-04 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 8.0856e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 6.9162e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 6.9863e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 6.1401e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 5.8093e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001212\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 49, Time Steps = 120, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 8, Min LR = 0.000097\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "257/257 [==============================] - 6s 13ms/step - loss: 0.6954 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 0.0015 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 9.4627e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 8.3428e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.8066e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.9597e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.4674e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 5.9902e-04 - val_loss: 0.0080 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.0290e-04 - val_loss: 9.8681e-04 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 5.7015e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Validation Loss: 0.000987\n",
      "New best for swarm at iteration 4: [2.56000000e+02 4.94505839e+01 1.20000000e+02 9.38854516e+00\n",
      " 1.00000000e-01 8.87661456e+00 9.68245108e-05] 0.000986808561719954\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 51, Time Steps = 116, Early Stopping Patience = 12, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000058\n",
      "X_train shape: (12567, 116, 5), X_test shape: (3142, 116, 5)\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 6s 13ms/step - loss: 0.7239 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 8.3630e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 7.6570e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.9386e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.4137e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.1988e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.4555e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.2909e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Validation Loss: 0.001609\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 80, Time Steps = 94, Early Stopping Patience = 10, Reduce LR Factor = 0.10, Reduce LR Patience = 6, Min LR = 0.000100\n",
      "X_train shape: (12584, 94, 5), X_test shape: (3147, 94, 5)\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 5s 15ms/step - loss: 1.1339 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 0.0025 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 0.0013 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 9.9053e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 8.7322e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 7.4846e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 7.1998e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 6.6548e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 6.1977e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 2s 10ms/step - loss: 6.1246e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Validation Loss: 0.001173\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 197, Batch Size = 74, Time Steps = 120, Early Stopping Patience = 12, Reduce LR Factor = 0.27, Reduce LR Patience = 7, Min LR = 0.000083\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 6s 19ms/step - loss: 0.9296 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 0.0025 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 8.4598e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 7.6713e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 7.1696e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 6.8758e-04 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 7.2037e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 5.8952e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Validation Loss: 0.001535\n",
      "Best after iteration 4: [2.56000000e+02 4.94505839e+01 1.20000000e+02 9.38854516e+00\n",
      " 1.00000000e-01 8.87661456e+00 9.68245108e-05] 0.000986808561719954\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 51, Time Steps = 117, Early Stopping Patience = 10, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000089\n",
      "X_train shape: (12566, 117, 5), X_test shape: (3142, 117, 5)\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 6s 13ms/step - loss: 0.7230 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 0.0015 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 9.7063e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 8.0322e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 7.2249e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 7.0410e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.5587e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 6.5745e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 5.5746e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 5.5305e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Validation Loss: 0.001130\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 59, Time Steps = 108, Early Stopping Patience = 8, Reduce LR Factor = 0.18, Reduce LR Patience = 8, Min LR = 0.000090\n",
      "X_train shape: (12573, 108, 5), X_test shape: (3144, 108, 5)\n",
      "Epoch 1/10\n",
      "214/214 [==============================] - 6s 13ms/step - loss: 0.8368 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 0.0011 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 8.4087e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 7.9651e-04 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 7.2083e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 6.2295e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 5.8130e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 6.0011e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 2s 10ms/step - loss: 5.4475e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Validation Loss: 0.001137\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 49, Time Steps = 120, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 8, Min LR = 0.000095\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "257/257 [==============================] - 6s 13ms/step - loss: 0.6985 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 0.0016 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 0.0010 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 8.4110e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 7.7068e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 7.0038e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.7586e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.3430e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 5.7446e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 5.7662e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001075\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 50, Time Steps = 120, Early Stopping Patience = 11, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000078\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "252/252 [==============================] - 6s 13ms/step - loss: 0.7107 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 0.0015 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 9.8839e-04 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 8.1560e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 7.4777e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 8.0309e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 6.5492e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 6.2890e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 5.7143e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "252/252 [==============================] - 3s 10ms/step - loss: 5.4411e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001083\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 245, Batch Size = 69, Time Steps = 99, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000100\n",
      "X_train shape: (12580, 99, 5), X_test shape: (3146, 99, 5)\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 6s 17ms/step - loss: 0.9566 - val_loss: 0.0071 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 2s 14ms/step - loss: 0.0020 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 9.0943e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 8.2815e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 7.3544e-04 - val_loss: 0.0071 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 7.5435e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 6.8721e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 6.0995e-04 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 5.8007e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001172\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 72, Time Steps = 120, Early Stopping Patience = 10, Reduce LR Factor = 0.20, Reduce LR Patience = 7, Min LR = 0.000096\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 6s 17ms/step - loss: 1.0193 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.0021 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 9.5373e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 7.8852e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 7.4164e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 6.8482e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 6.1904e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 6.1677e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 6.3355e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Validation Loss: 0.001111\n",
      "Best after iteration 5: [2.56000000e+02 4.94505839e+01 1.20000000e+02 9.38854516e+00\n",
      " 1.00000000e-01 8.87661456e+00 9.68245108e-05] 0.000986808561719954\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 53, Time Steps = 118, Early Stopping Patience = 10, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000091\n",
      "X_train shape: (12565, 118, 5), X_test shape: (3142, 118, 5)\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 6s 13ms/step - loss: 0.7549 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 8.6607e-04 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 7.3260e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 6.8153e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 6.3788e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 6.5143e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 5.6228e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "238/238 [==============================] - 2s 10ms/step - loss: 5.7866e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Validation Loss: 0.001323\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 54, Time Steps = 111, Early Stopping Patience = 8, Reduce LR Factor = 0.14, Reduce LR Patience = 9, Min LR = 0.000099\n",
      "X_train shape: (12571, 111, 5), X_test shape: (3143, 111, 5)\n",
      "Epoch 1/10\n",
      "233/233 [==============================] - 6s 13ms/step - loss: 0.7664 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 9.5381e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 7.6890e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 7.1586e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 6.3856e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 6.4802e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 6.1089e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 5.1357e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 2s 10ms/step - loss: 5.9752e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Validation Loss: 0.001059\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 49, Time Steps = 120, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 8, Min LR = 0.000095\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "257/257 [==============================] - 6s 13ms/step - loss: 0.6950 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 0.0014 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 0.0010 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 8.3745e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 7.2627e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 7.0735e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.0462e-04 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.2563e-04 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 6.1950e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 5.4700e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Validation Loss: 0.001168\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 56, Time Steps = 120, Early Stopping Patience = 10, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000078\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 6s 13ms/step - loss: 0.7930 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0016 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 9.6142e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 8.2601e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 7.1353e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 6.5351e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 6.2956e-04 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 6.2876e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 5.6494e-04 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 5.8813e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Validation Loss: 0.001084\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 238, Batch Size = 60, Time Steps = 106, Early Stopping Patience = 11, Reduce LR Factor = 0.10, Reduce LR Patience = 7, Min LR = 0.000100\n",
      "X_train shape: (12575, 106, 5), X_test shape: (3144, 106, 5)\n",
      "Epoch 1/10\n",
      "210/210 [==============================] - 7s 16ms/step - loss: 0.8221 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.0017 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.0010 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 8.1981e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 7.9240e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 6.8895e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 6.5503e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 5.8022e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 5.8381e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 5.1069e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Validation Loss: 0.001012\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 60, Time Steps = 120, Early Stopping Patience = 9, Reduce LR Factor = 0.12, Reduce LR Patience = 8, Min LR = 0.000100\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "210/210 [==============================] - 6s 14ms/step - loss: 0.8521 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.0017 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.0010 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 8.2860e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 7.4968e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 6.9545e-04 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 6.5567e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 6.5113e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 5.8464e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 6.0728e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Validation Loss: 0.001529\n",
      "Best after iteration 6: [2.56000000e+02 4.94505839e+01 1.20000000e+02 9.38854516e+00\n",
      " 1.00000000e-01 8.87661456e+00 9.68245108e-05] 0.000986808561719954\n",
      "Stopping search: maximum iterations reached --> 6\n",
      "\n",
      "Best Hyperparameters: LSTM Units = 256, Batch Size = 49, Time Steps = 120, Early Stopping Patience = 9, Reduce LR Factor = 0.10, Reduce LR Patience = 8, Min LR = 0.000097\n",
      "Best Validation Loss = 0.000987\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pyswarm\n",
    "from pyswarm import pso\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "param_ranges = {\n",
    "    \"lstm_units\": (32, 256),           # Range for LSTM units\n",
    "    \"batch_size\": (16, 128),           # Range for batch size\n",
    "    \"time_steps\": (30, 120),           # Range for sequence length\n",
    "    \"early_stopping_patience\": (5, 20),  # Range for early stopping patience\n",
    "    \"reduce_lr_factor\": (0.1, 0.5),      # Range for reduce_lr factor\n",
    "    \"reduce_lr_patience\": (2, 10),       # Range for reduce_lr patience\n",
    "    \"reduce_lr_min_lr\": (1e-6, 1e-4)     # Range for minimum learning rate\n",
    "}\n",
    "\n",
    "bounds = [\n",
    "    param_ranges[\"lstm_units\"],            # Bounds for LSTM units\n",
    "    param_ranges[\"batch_size\"],            # Bounds for batch size\n",
    "    param_ranges[\"time_steps\"],            # Bounds for sequence length\n",
    "    param_ranges[\"early_stopping_patience\"],  # Bounds for early stopping patience\n",
    "    param_ranges[\"reduce_lr_factor\"],         # Bounds for reduce_lr factor\n",
    "    param_ranges[\"reduce_lr_patience\"],       # Bounds for reduce_lr patience\n",
    "    param_ranges[\"reduce_lr_min_lr\"]          # Bounds for reduce_lr min_lr\n",
    "]\n",
    "\n",
    "def objective_function(params):\n",
    "    lstm_units = int(params[0])\n",
    "    batch_size = int(params[1])\n",
    "    time_steps = int(params[2])\n",
    "    early_stopping_patience = int(params[3])\n",
    "    reduce_lr_factor = float(params[4])\n",
    "    reduce_lr_patience = int(params[5])\n",
    "    reduce_lr_min_lr = float(params[6])\n",
    "    \n",
    "    print(f\"\\nTrying Hyperparameters: LSTM Units = {lstm_units}, Batch Size = {batch_size}, \"\n",
    "          f\"Time Steps = {time_steps}, Early Stopping Patience = {early_stopping_patience}, \"\n",
    "          f\"Reduce LR Factor = {reduce_lr_factor:.2f}, Reduce LR Patience = {reduce_lr_patience}, \"\n",
    "          f\"Min LR = {reduce_lr_min_lr:.6f}\")\n",
    "\n",
    "    # Updating sequence length for data creation\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    X, y = create_dataset(model_scaled_features, model_scaled_target, time_steps)\n",
    "    train_size = int(0.80 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Converting to tensors\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "    \n",
    "    input_shape = (time_steps, X_train.shape[2])\n",
    "    print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "\n",
    "    # Defining the new model architecture\n",
    "    model = Sequential([\n",
    "        # First LSTM layer with regularization\n",
    "        LSTM(lstm_units, return_sequences=True,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01),\n",
    "             input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Second LSTM layer\n",
    "        LSTM(lstm_units, return_sequences=False,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Output layer\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=early_stopping_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=reduce_lr_factor,\n",
    "        patience=reduce_lr_patience,\n",
    "        min_lr=reduce_lr_min_lr\n",
    "    )\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        X_train_tensor, y_train_tensor,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_tensor, y_test_tensor),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Getting validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Running PSO with the new model\n",
    "best_params, best_loss = pso(\n",
    "    objective_function,\n",
    "    lb=[b[0] for b in bounds],  # Lower bounds\n",
    "    ub=[b[1] for b in bounds],  # Upper bounds\n",
    "    swarmsize=6,               # Number of particles\n",
    "    maxiter=6,                 # Number of iterations\n",
    "    debug=True                  # Enable logging\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: LSTM Units = {int(best_params[0])}, Batch Size = {int(best_params[1])}, \"\n",
    "      f\"Time Steps = {int(best_params[2])}, Early Stopping Patience = {int(best_params[3])}, \"\n",
    "      f\"Reduce LR Factor = {best_params[4]:.2f}, Reduce LR Patience = {int(best_params[5])}, \"\n",
    "      f\"Min LR = {best_params[6]:.6f}\")\n",
    "print(f\"Best Validation Loss = {best_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19ba5e-cb70-45ba-afd9-c4e8ca8353f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9f2f1-7bd8-4c42-a753-50b0b9f58136",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSO (7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb52a03-e2d6-4a23-a254-06e6a34e75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 157, Batch Size = 83, Time Steps = 84, Early Stopping Patience = 12, Reduce LR Factor = 0.20, Reduce LR Patience = 2, Min LR = 0.000029\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 5s 14ms/step - loss: 0.9331 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 0.0015 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 8.6435e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 7.7699e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.5370e-04 - val_loss: 0.0023 - lr: 2.0279e-04\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.3416e-04 - val_loss: 0.0013 - lr: 2.0279e-04\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1608e-04 - val_loss: 0.0014 - lr: 2.0279e-04\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 6.1712e-04 - val_loss: 0.0017 - lr: 2.0279e-04\n",
      "Validation Loss: 0.001346\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 209, Batch Size = 94, Time Steps = 86, Early Stopping Patience = 16, Reduce LR Factor = 0.45, Reduce LR Patience = 7, Min LR = 0.000052\n",
      "X_train shape: (12591, 86, 5), X_test shape: (3148, 86, 5)\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 5s 17ms/step - loss: 1.2043 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.0036 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.0016 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 0.0011 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 9.1367e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 7.8990e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 7.0338e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 6.6548e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 6.2808e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 6.0584e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Validation Loss: 0.001179\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 176, Batch Size = 20, Time Steps = 112, Early Stopping Patience = 11, Reduce LR Factor = 0.14, Reduce LR Patience = 2, Min LR = 0.000015\n",
      "X_train shape: (12570, 112, 5), X_test shape: (3143, 112, 5)\n",
      "Epoch 1/10\n",
      "629/629 [==============================] - 9s 9ms/step - loss: 0.2398 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 0.0010 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 7.6828e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 7.3734e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 7.2570e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 4.7848e-04 - val_loss: 0.0018 - lr: 1.4104e-04\n",
      "Epoch 7/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 4.7085e-04 - val_loss: 0.0025 - lr: 1.4104e-04\n",
      "Epoch 8/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 4.3343e-04 - val_loss: 0.0013 - lr: 1.9893e-05\n",
      "Epoch 9/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 4.3150e-04 - val_loss: 0.0013 - lr: 1.9893e-05\n",
      "Epoch 10/10\n",
      "629/629 [==============================] - 5s 8ms/step - loss: 4.2854e-04 - val_loss: 0.0019 - lr: 1.9893e-05\n",
      "Validation Loss: 0.001276\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 53, Batch Size = 117, Time Steps = 34, Early Stopping Patience = 15, Reduce LR Factor = 0.23, Reduce LR Patience = 5, Min LR = 0.000034\n",
      "X_train shape: (12632, 34, 5), X_test shape: (3159, 34, 5)\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 4s 13ms/step - loss: 0.7588 - val_loss: 0.1644 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 9.5496e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 8.7603e-04 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 8.1186e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Validation Loss: 0.002798\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 108, Batch Size = 76, Time Steps = 114, Early Stopping Patience = 16, Reduce LR Factor = 0.31, Reduce LR Patience = 6, Min LR = 0.000025\n",
      "X_train shape: (12568, 114, 5), X_test shape: (3143, 114, 5)\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 5s 13ms/step - loss: 0.7246 - val_loss: 0.0145 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 0.0041 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 0.0014 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 8.7640e-04 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 7.5720e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 7.0908e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 7.0238e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 5.9624e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 2s 9ms/step - loss: 5.8278e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Validation Loss: 0.001223\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 149, Batch Size = 34, Time Steps = 69, Early Stopping Patience = 7, Reduce LR Factor = 0.29, Reduce LR Patience = 2, Min LR = 0.000075\n",
      "X_train shape: (12604, 69, 5), X_test shape: (3152, 69, 5)\n",
      "Epoch 1/10\n",
      "371/371 [==============================] - 6s 9ms/step - loss: 0.3770 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 0.0012 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 8.8538e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 8.1520e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 6.9210e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 5.6611e-04 - val_loss: 0.0041 - lr: 2.8990e-04\n",
      "Epoch 7/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 5.5285e-04 - val_loss: 0.0030 - lr: 2.8990e-04\n",
      "Epoch 8/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 5.0604e-04 - val_loss: 0.0015 - lr: 8.4043e-05\n",
      "Epoch 9/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 4.9592e-04 - val_loss: 0.0015 - lr: 8.4043e-05\n",
      "Epoch 10/10\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 4.9321e-04 - val_loss: 0.0026 - lr: 8.4043e-05\n",
      "Validation Loss: 0.001496\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 59, Batch Size = 38, Time Steps = 104, Early Stopping Patience = 5, Reduce LR Factor = 0.40, Reduce LR Patience = 2, Min LR = 0.000035\n",
      "X_train shape: (12576, 104, 5), X_test shape: (3145, 104, 5)\n",
      "Epoch 1/10\n",
      "331/331 [==============================] - 7s 10ms/step - loss: 0.2836 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 0.0018 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 0.0011 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 8.8061e-04 - val_loss: 0.0029 - lr: 3.9751e-04\n",
      "Epoch 5/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 8.1914e-04 - val_loss: 0.0040 - lr: 3.9751e-04\n",
      "Epoch 6/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 7.5843e-04 - val_loss: 0.0024 - lr: 3.9751e-04\n",
      "Epoch 7/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 7.1097e-04 - val_loss: 0.0044 - lr: 3.9751e-04\n",
      "Epoch 8/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 6.6680e-04 - val_loss: 0.0028 - lr: 3.9751e-04\n",
      "Epoch 9/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 6.3597e-04 - val_loss: 0.0029 - lr: 1.5802e-04\n",
      "Epoch 10/10\n",
      "331/331 [==============================] - 3s 8ms/step - loss: 6.1568e-04 - val_loss: 0.0024 - lr: 1.5802e-04\n",
      "Validation Loss: 0.002388\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 95, Batch Size = 120, Time Steps = 87, Early Stopping Patience = 15, Reduce LR Factor = 0.32, Reduce LR Patience = 2, Min LR = 0.000059\n",
      "X_train shape: (12590, 87, 5), X_test shape: (3148, 87, 5)\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 4s 15ms/step - loss: 1.0477 - val_loss: 0.1149 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0319 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0031 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 9.9864e-04 - val_loss: 0.0026 - lr: 3.2032e-04\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 9.4313e-04 - val_loss: 0.0034 - lr: 3.2032e-04\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 9.0077e-04 - val_loss: 0.0035 - lr: 3.2032e-04\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 8.7069e-04 - val_loss: 0.0030 - lr: 1.0261e-04\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 8.5238e-04 - val_loss: 0.0032 - lr: 1.0261e-04\n",
      "Validation Loss: 0.002554\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 83, Time Steps = 83, Early Stopping Patience = 9, Reduce LR Factor = 0.27, Reduce LR Patience = 5, Min LR = 0.000037\n",
      "X_train shape: (12593, 83, 5), X_test shape: (3149, 83, 5)\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 5s 13ms/step - loss: 1.1731 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.8872e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.2993e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.0199e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6368e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6135e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4984e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.3927e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Validation Loss: 0.001147\n",
      "New best for swarm at iteration 1: [2.56000000e+02 8.34705170e+01 8.39522691e+01 9.90335145e+00\n",
      " 2.68743470e-01 5.95679427e+00 3.74341465e-05] 0.0011468887096270919\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 47, Time Steps = 105, Early Stopping Patience = 10, Reduce LR Factor = 0.34, Reduce LR Patience = 2, Min LR = 0.000001\n",
      "X_train shape: (12576, 105, 5), X_test shape: (3144, 105, 5)\n",
      "Epoch 1/10\n",
      "268/268 [==============================] - 6s 12ms/step - loss: 0.6656 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.5039e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.2414e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.0239e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.0925e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.3614e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 4.9419e-04 - val_loss: 0.0014 - lr: 3.3521e-04\n",
      "Epoch 9/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 4.9653e-04 - val_loss: 0.0014 - lr: 3.3521e-04\n",
      "Epoch 10/10\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 4.5686e-04 - val_loss: 0.0013 - lr: 1.1237e-04\n",
      "Validation Loss: 0.001205\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 32, Batch Size = 128, Time Steps = 30, Early Stopping Patience = 20, Reduce LR Factor = 0.37, Reduce LR Patience = 2, Min LR = 0.000001\n",
      "X_train shape: (12636, 30, 5), X_test shape: (3159, 30, 5)\n",
      "Epoch 1/10\n",
      "99/99 [==============================] - 4s 10ms/step - loss: 0.6073 - val_loss: 0.2270 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.1025 - val_loss: 0.0404 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 9.5226e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 8.6437e-04 - val_loss: 0.0029 - lr: 3.7383e-04\n",
      "Validation Loss: 0.002366\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 240, Batch Size = 78, Time Steps = 114, Early Stopping Patience = 15, Reduce LR Factor = 0.17, Reduce LR Patience = 9, Min LR = 0.000039\n",
      "X_train shape: (12568, 114, 5), X_test shape: (3143, 114, 5)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 15ms/step - loss: 1.0696 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0023 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 9.8976e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.9917e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.3458e-04 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.0555e-04 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.3772e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.1530e-04 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.4324e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Validation Loss: 0.001484\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 240, Batch Size = 89, Time Steps = 59, Early Stopping Patience = 15, Reduce LR Factor = 0.20, Reduce LR Patience = 6, Min LR = 0.000055\n",
      "X_train shape: (12612, 59, 5), X_test shape: (3154, 59, 5)\n",
      "Epoch 1/10\n",
      "142/142 [==============================] - 5s 13ms/step - loss: 1.2219 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 9.9329e-04 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 8.3853e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 7.4358e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 6.6572e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 6.2333e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 5.9953e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 5.7892e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Validation Loss: 0.001379\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 44, Batch Size = 16, Time Steps = 71, Early Stopping Patience = 5, Reduce LR Factor = 0.46, Reduce LR Patience = 6, Min LR = 0.000082\n",
      "X_train shape: (12603, 71, 5), X_test shape: (3151, 71, 5)\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 8s 6ms/step - loss: 0.1060 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 0.0012 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 9.6236e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 8.2586e-04 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 7.8459e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 7.6031e-04 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 7.1845e-04 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 4s 5ms/step - loss: 7.0160e-04 - val_loss: 0.0080 - lr: 0.0010\n",
      "Validation Loss: 0.004970\n",
      "Best after iteration 1: [2.56000000e+02 8.34705170e+01 8.39522691e+01 9.90335145e+00\n",
      " 2.68743470e-01 5.95679427e+00 3.74341465e-05] 0.0011468887096270919\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 120, Batch Size = 111, Time Steps = 86, Early Stopping Patience = 14, Reduce LR Factor = 0.34, Reduce LR Patience = 2, Min LR = 0.000062\n",
      "X_train shape: (12591, 86, 5), X_test shape: (3148, 86, 5)\n",
      "Epoch 1/10\n",
      "114/114 [==============================] - 5s 14ms/step - loss: 1.0848 - val_loss: 0.0631 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.0149 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 9.1131e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 7.9230e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 7.5229e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 6.7013e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 6.7100e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Validation Loss: 0.001336\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 77, Time Steps = 82, Early Stopping Patience = 6, Reduce LR Factor = 0.18, Reduce LR Patience = 5, Min LR = 0.000030\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 5s 13ms/step - loss: 1.0893 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 9.1602e-04 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 8.0963e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 7.1683e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.6457e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.0917e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 5.7888e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.0556e-04 - val_loss: 9.4549e-04 - lr: 0.0010\n",
      "Validation Loss: 0.000945\n",
      "New best for swarm at iteration 2: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 62, Time Steps = 95, Early Stopping Patience = 8, Reduce LR Factor = 0.42, Reduce LR Patience = 2, Min LR = 0.000001\n",
      "X_train shape: (12584, 95, 5), X_test shape: (3146, 95, 5)\n",
      "Epoch 1/10\n",
      "203/203 [==============================] - 5s 13ms/step - loss: 0.8780 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.0011 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 8.7130e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 7.8411e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 6.9896e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 6.9767e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 6.0706e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 5.4642e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 4.7605e-04 - val_loss: 0.0031 - lr: 4.1965e-04\n",
      "Validation Loss: 0.001103\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 96, Batch Size = 126, Time Steps = 36, Early Stopping Patience = 18, Reduce LR Factor = 0.38, Reduce LR Patience = 2, Min LR = 0.000001\n",
      "X_train shape: (12631, 36, 5), X_test shape: (3158, 36, 5)\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 4s 14ms/step - loss: 1.1006 - val_loss: 0.1338 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 8.9716e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 8.4762e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 0s 5ms/step - loss: 7.9376e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Validation Loss: 0.002234\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 250, Batch Size = 79, Time Steps = 103, Early Stopping Patience = 13, Reduce LR Factor = 0.10, Reduce LR Patience = 9, Min LR = 0.000042\n",
      "X_train shape: (12577, 103, 5), X_test shape: (3145, 103, 5)\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 6s 18ms/step - loss: 1.1050 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0013 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 9.8120e-04 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 8.3821e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 7.1673e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 6.6039e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 6.5941e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 6.0177e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 5.8928e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Validation Loss: 0.001023\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 112, Time Steps = 65, Early Stopping Patience = 17, Reduce LR Factor = 0.14, Reduce LR Patience = 8, Min LR = 0.000038\n",
      "X_train shape: (12608, 65, 5), X_test shape: (3152, 65, 5)\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 5s 14ms/step - loss: 1.5793 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.7540e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.4087e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.7602e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.3368e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.6270e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 6.9080e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001127\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 74, Batch Size = 24, Time Steps = 61, Early Stopping Patience = 5, Reduce LR Factor = 0.37, Reduce LR Patience = 8, Min LR = 0.000072\n",
      "X_train shape: (12611, 61, 5), X_test shape: (3153, 61, 5)\n",
      "Epoch 1/10\n",
      "526/526 [==============================] - 7s 7ms/step - loss: 0.1959 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 0.0011 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 8.9267e-04 - val_loss: 0.0035 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 7.5826e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 6.7974e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 6.9995e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 6.3214e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 6.3179e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 5.9931e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "526/526 [==============================] - 3s 6ms/step - loss: 6.3335e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Validation Loss: 0.001864\n",
      "Best after iteration 2: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 174, Batch Size = 97, Time Steps = 86, Early Stopping Patience = 11, Reduce LR Factor = 0.31, Reduce LR Patience = 2, Min LR = 0.000063\n",
      "X_train shape: (12591, 86, 5), X_test shape: (3148, 86, 5)\n",
      "Epoch 1/10\n",
      "130/130 [==============================] - 5s 16ms/step - loss: 1.1449 - val_loss: 0.0220 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0066 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0016 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 9.5846e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 8.5092e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 7.1922e-04 - val_loss: 0.0025 - lr: 3.0794e-04\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 6.9689e-04 - val_loss: 0.0025 - lr: 3.0794e-04\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 6.6548e-04 - val_loss: 0.0025 - lr: 9.4828e-05\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 1s 11ms/step - loss: 6.6065e-04 - val_loss: 0.0018 - lr: 9.4828e-05\n",
      "Validation Loss: 0.001667\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 74, Time Steps = 82, Early Stopping Patience = 5, Reduce LR Factor = 0.13, Reduce LR Patience = 4, Min LR = 0.000026\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 5s 13ms/step - loss: 1.0462 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 9.0841e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 7.8697e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 7.3510e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 6.5686e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 6.4149e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 5.9594e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 5.7247e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Validation Loss: 0.001044\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 70, Time Steps = 88, Early Stopping Patience = 7, Reduce LR Factor = 0.46, Reduce LR Patience = 2, Min LR = 0.000002\n",
      "X_train shape: (12589, 88, 5), X_test shape: (3148, 88, 5)\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 5s 13ms/step - loss: 0.9904 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0022 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 9.4280e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 8.4564e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 6.9242e-04 - val_loss: 0.0013 - lr: 4.5526e-04\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 6.6198e-04 - val_loss: 0.0016 - lr: 4.5526e-04\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 6.1254e-04 - val_loss: 0.0020 - lr: 4.5526e-04\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 5.7678e-04 - val_loss: 0.0021 - lr: 2.0726e-04\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 5.6611e-04 - val_loss: 0.0020 - lr: 2.0726e-04\n",
      "Validation Loss: 0.001314\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 183, Batch Size = 123, Time Steps = 52, Early Stopping Patience = 16, Reduce LR Factor = 0.29, Reduce LR Patience = 3, Min LR = 0.000009\n",
      "X_train shape: (12618, 52, 5), X_test shape: (3155, 52, 5)\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - 5s 15ms/step - loss: 1.4756 - val_loss: 0.0513 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0060 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 9.2618e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 8.1517e-04 - val_loss: 0.0029 - lr: 2.9500e-04\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 7.7146e-04 - val_loss: 0.0029 - lr: 2.9500e-04\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 7.4612e-04 - val_loss: 0.0023 - lr: 2.9500e-04\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 7.3329e-04 - val_loss: 0.0021 - lr: 2.9500e-04\n",
      "Validation Loss: 0.002087\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 79, Time Steps = 89, Early Stopping Patience = 12, Reduce LR Factor = 0.10, Reduce LR Patience = 9, Min LR = 0.000038\n",
      "X_train shape: (12588, 89, 5), X_test shape: (3148, 89, 5)\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 5s 13ms/step - loss: 1.1153 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 9.5544e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 8.1379e-04 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 7.3306e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 7.1439e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 6.3402e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 6.1322e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 1s 9ms/step - loss: 5.7353e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Validation Loss: 0.001453\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 114, Time Steps = 75, Early Stopping Patience = 15, Reduce LR Factor = 0.12, Reduce LR Patience = 8, Min LR = 0.000027\n",
      "X_train shape: (12600, 75, 5), X_test shape: (3150, 75, 5)\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 5s 17ms/step - loss: 1.6066 - val_loss: 0.0187 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 9.6270e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 8.2588e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 7.5531e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 7.1803e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 6.0741e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 1s 9ms/step - loss: 5.8360e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001033\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 99, Batch Size = 38, Time Steps = 57, Early Stopping Patience = 5, Reduce LR Factor = 0.26, Reduce LR Patience = 7, Min LR = 0.000052\n",
      "X_train shape: (12614, 57, 5), X_test shape: (3154, 57, 5)\n",
      "Epoch 1/10\n",
      "332/332 [==============================] - 6s 9ms/step - loss: 0.3503 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 0.0014 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 9.7907e-04 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 8.5636e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 7.3861e-04 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 7.0100e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 6.5764e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 6.1749e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 6.0311e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "332/332 [==============================] - 2s 6ms/step - loss: 5.6938e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Validation Loss: 0.001361\n",
      "Best after iteration 3: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 214, Batch Size = 83, Time Steps = 85, Early Stopping Patience = 9, Reduce LR Factor = 0.29, Reduce LR Patience = 3, Min LR = 0.000055\n",
      "X_train shape: (12592, 85, 5), X_test shape: (3148, 85, 5)\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 6s 17ms/step - loss: 1.0819 - val_loss: 0.0131 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.0029 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.0014 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 9.9351e-04 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 8.8993e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.2322e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 7.4356e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 6.6431e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9468e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 5.9093e-04 - val_loss: 0.0036 - lr: 0.0010\n",
      "Validation Loss: 0.001360\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 75, Time Steps = 82, Early Stopping Patience = 5, Reduce LR Factor = 0.14, Reduce LR Patience = 4, Min LR = 0.000027\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 5s 13ms/step - loss: 1.0599 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 8.9499e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 7.8582e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 7.1820e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 6.3336e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 5.8613e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 5.5398e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 5.3973e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Validation Loss: 0.001044\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 76, Time Steps = 87, Early Stopping Patience = 6, Reduce LR Factor = 0.35, Reduce LR Patience = 3, Min LR = 0.000003\n",
      "X_train shape: (12590, 87, 5), X_test shape: (3148, 87, 5)\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 5s 13ms/step - loss: 1.0751 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 9.4291e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 8.6619e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 6.8307e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 6.5630e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 6.3705e-04 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 5.3237e-04 - val_loss: 0.0013 - lr: 3.4796e-04\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 5.0324e-04 - val_loss: 0.0019 - lr: 3.4796e-04\n",
      "Validation Loss: 0.001299\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 246, Batch Size = 104, Time Steps = 66, Early Stopping Patience = 14, Reduce LR Factor = 0.20, Reduce LR Patience = 4, Min LR = 0.000014\n",
      "X_train shape: (12607, 66, 5), X_test shape: (3152, 66, 5)\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 5s 16ms/step - loss: 1.4381 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 9.4002e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.8636e-04 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 7.3046e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.8122e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.2891e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 6.5147e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001210\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 78, Time Steps = 85, Early Stopping Patience = 12, Reduce LR Factor = 0.10, Reduce LR Patience = 9, Min LR = 0.000034\n",
      "X_train shape: (12592, 85, 5), X_test shape: (3148, 85, 5)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 5s 13ms/step - loss: 1.1027 - val_loss: 0.0063 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 9.1978e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 7.8365e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 7.3232e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 6.7249e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 7.2466e-04 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 5.9449e-04 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 6.1378e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001231\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 101, Time Steps = 82, Early Stopping Patience = 12, Reduce LR Factor = 0.14, Reduce LR Patience = 7, Min LR = 0.000023\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 5s 14ms/step - loss: 1.4259 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0036 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 9.4355e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 7.6449e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 7.2895e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 6.5952e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 6.4208e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.9129e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Validation Loss: 0.001295\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 175, Batch Size = 48, Time Steps = 61, Early Stopping Patience = 5, Reduce LR Factor = 0.20, Reduce LR Patience = 6, Min LR = 0.000031\n",
      "X_train shape: (12611, 61, 5), X_test shape: (3153, 61, 5)\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 5s 9ms/step - loss: 0.5690 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 0.0015 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 9.7177e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 7.7706e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 7.0132e-04 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 6.6793e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 6.1230e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 5.9599e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 5.6699e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Validation Loss: 0.001334\n",
      "Best after iteration 4: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 235, Batch Size = 78, Time Steps = 84, Early Stopping Patience = 9, Reduce LR Factor = 0.29, Reduce LR Patience = 4, Min LR = 0.000051\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 16ms/step - loss: 1.0594 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.0024 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.0013 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 9.8324e-04 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 8.8574e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 7.3533e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 7.0620e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 6.2452e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 5.8500e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 6.0503e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Validation Loss: 0.001408\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 76, Time Steps = 82, Early Stopping Patience = 6, Reduce LR Factor = 0.16, Reduce LR Patience = 5, Min LR = 0.000029\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 5s 13ms/step - loss: 1.0754 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 9.6322e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 8.4783e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 8.0417e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 6.7430e-04 - val_loss: 0.0073 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 6.6003e-04 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 6.1482e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 1s 8ms/step - loss: 6.0523e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Validation Loss: 0.001141\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 73, Time Steps = 86, Early Stopping Patience = 6, Reduce LR Factor = 0.30, Reduce LR Patience = 3, Min LR = 0.000010\n",
      "X_train shape: (12591, 86, 5), X_test shape: (3148, 86, 5)\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 5s 13ms/step - loss: 1.0317 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0012 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 9.1814e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 8.0596e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 6.8261e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 6.3254e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 5.4695e-04 - val_loss: 0.0012 - lr: 3.0323e-04\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 5.1259e-04 - val_loss: 0.0010 - lr: 3.0323e-04\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 5.0371e-04 - val_loss: 0.0014 - lr: 3.0323e-04\n",
      "Validation Loss: 0.001040\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 86, Time Steps = 74, Early Stopping Patience = 11, Reduce LR Factor = 0.14, Reduce LR Patience = 5, Min LR = 0.000019\n",
      "X_train shape: (12600, 74, 5), X_test shape: (3151, 74, 5)\n",
      "Epoch 1/10\n",
      "147/147 [==============================] - 5s 13ms/step - loss: 1.2145 - val_loss: 0.0132 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 9.6107e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 8.5315e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 7.3190e-04 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 7.0308e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 6.4007e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 6.0272e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 5.6527e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Validation Loss: 0.001249\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 255, Batch Size = 78, Time Steps = 87, Early Stopping Patience = 12, Reduce LR Factor = 0.12, Reduce LR Patience = 8, Min LR = 0.000031\n",
      "X_train shape: (12590, 87, 5), X_test shape: (3148, 87, 5)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 17ms/step - loss: 1.1012 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.0012 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 9.2676e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 8.1403e-04 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.6197e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 7.5723e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.3416e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 6.1116e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 5.8489e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Validation Loss: 0.001502\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 95, Time Steps = 83, Early Stopping Patience = 10, Reduce LR Factor = 0.15, Reduce LR Patience = 6, Min LR = 0.000022\n",
      "X_train shape: (12593, 83, 5), X_test shape: (3149, 83, 5)\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 14ms/step - loss: 1.3411 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 8.7260e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 8.2025e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 7.1008e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 6.3334e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 6.1278e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 5.8074e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Validation Loss: 0.001181\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 245, Batch Size = 54, Time Steps = 66, Early Stopping Patience = 5, Reduce LR Factor = 0.16, Reduce LR Patience = 5, Min LR = 0.000020\n",
      "X_train shape: (12607, 66, 5), X_test shape: (3152, 66, 5)\n",
      "Epoch 1/10\n",
      "234/234 [==============================] - 6s 11ms/step - loss: 0.7469 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.0016 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 0.0010 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 8.0771e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 7.6608e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 6.7221e-04 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 5.8763e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 6.7745e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 5.7581e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "234/234 [==============================] - 2s 8ms/step - loss: 5.5709e-04 - val_loss: 9.9617e-04 - lr: 0.0010\n",
      "Validation Loss: 0.000996\n",
      "Best after iteration 5: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 212, Batch Size = 83, Time Steps = 84, Early Stopping Patience = 8, Reduce LR Factor = 0.28, Reduce LR Patience = 4, Min LR = 0.000048\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "152/152 [==============================] - 5s 13ms/step - loss: 1.0726 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 9.6668e-04 - val_loss: 0.0065 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 8.1998e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 7.1096e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.6396e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.8262e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 6.3845e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 5.4450e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Validation Loss: 0.001294\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 77, Time Steps = 82, Early Stopping Patience = 7, Reduce LR Factor = 0.18, Reduce LR Patience = 5, Min LR = 0.000031\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 5s 14ms/step - loss: 1.0887 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 9.4192e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 7.9792e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 7.6961e-04 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.1498e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.2467e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 6.0899e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 5.6402e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Validation Loss: 0.001365\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 74, Time Steps = 85, Early Stopping Patience = 6, Reduce LR Factor = 0.24, Reduce LR Patience = 3, Min LR = 0.000020\n",
      "X_train shape: (12592, 85, 5), X_test shape: (3148, 85, 5)\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 5s 13ms/step - loss: 1.0490 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 2s 9ms/step - loss: 9.4179e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 8.3557e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 7.1318e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 6.4911e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 5.6649e-04 - val_loss: 0.0013 - lr: 2.3711e-04\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 5.4117e-04 - val_loss: 0.0022 - lr: 2.3711e-04\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 5.2763e-04 - val_loss: 0.0017 - lr: 2.3711e-04\n",
      "Validation Loss: 0.001174\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 74, Time Steps = 75, Early Stopping Patience = 8, Reduce LR Factor = 0.15, Reduce LR Patience = 5, Min LR = 0.000021\n",
      "X_train shape: (12600, 75, 5), X_test shape: (3150, 75, 5)\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 5s 13ms/step - loss: 1.0441 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 9.6655e-04 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 8.1981e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 6.9941e-04 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 7.1201e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 6.2486e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 5.3838e-04 - val_loss: 0.0025 - lr: 1.5204e-04\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 5.2544e-04 - val_loss: 0.0025 - lr: 1.5204e-04\n",
      "Validation Loss: 0.001841\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 255, Batch Size = 77, Time Steps = 89, Early Stopping Patience = 10, Reduce LR Factor = 0.13, Reduce LR Patience = 7, Min LR = 0.000034\n",
      "X_train shape: (12588, 89, 5), X_test shape: (3148, 89, 5)\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 6s 17ms/step - loss: 1.0875 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 9.2033e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 8.0428e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 7.2954e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 2s 11ms/step - loss: 6.4929e-04 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 6.1306e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 6.1779e-04 - val_loss: 0.0072 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 2s 11ms/step - loss: 5.6369e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Validation Loss: 0.001312\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 94, Time Steps = 82, Early Stopping Patience = 9, Reduce LR Factor = 0.16, Reduce LR Patience = 6, Min LR = 0.000025\n",
      "X_train shape: (12594, 82, 5), X_test shape: (3149, 82, 5)\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 5s 16ms/step - loss: 1.3305 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 9.2848e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 8.0666e-04 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 7.2991e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 6.7054e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 6.5756e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 6.3453e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Validation Loss: 0.001566\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 58, Time Steps = 72, Early Stopping Patience = 5, Reduce LR Factor = 0.15, Reduce LR Patience = 5, Min LR = 0.000019\n",
      "X_train shape: (12602, 72, 5), X_test shape: (3151, 72, 5)\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 5s 10ms/step - loss: 0.8191 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.0017 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.0010 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 8.0805e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 7.2910e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 6.6646e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 6.0389e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 5.7513e-04 - val_loss: 9.5688e-04 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 6.2692e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 5.5009e-04 - val_loss: 9.5155e-04 - lr: 0.0010\n",
      "Validation Loss: 0.000952\n",
      "Best after iteration 6: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 212, Batch Size = 85, Time Steps = 83, Early Stopping Patience = 7, Reduce LR Factor = 0.24, Reduce LR Patience = 5, Min LR = 0.000042\n",
      "X_train shape: (12593, 83, 5), X_test shape: (3149, 83, 5)\n",
      "Epoch 1/10\n",
      "149/149 [==============================] - 5s 14ms/step - loss: 1.0987 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0029 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 8.2934e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 7.3604e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 6.7988e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 6.5148e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 6.0973e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 1s 9ms/step - loss: 5.9012e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Validation Loss: 0.001191\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 77, Time Steps = 83, Early Stopping Patience = 7, Reduce LR Factor = 0.19, Reduce LR Patience = 5, Min LR = 0.000031\n",
      "X_train shape: (12593, 83, 5), X_test shape: (3149, 83, 5)\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 5s 14ms/step - loss: 1.0893 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.0023 - val_loss: 0.0070 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 8.7037e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 7.6144e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 7.0107e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 6.5270e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 6.0771e-04 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 1s 9ms/step - loss: 6.0042e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Validation Loss: 0.001101\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 76, Time Steps = 83, Early Stopping Patience = 6, Reduce LR Factor = 0.20, Reduce LR Patience = 4, Min LR = 0.000025\n",
      "X_train shape: (12593, 83, 5), X_test shape: (3149, 83, 5)\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 5s 13ms/step - loss: 1.0748 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 9.4705e-04 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 7.7664e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 6.8399e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 7.0711e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 6.4305e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 5.5214e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 1s 9ms/step - loss: 6.1991e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Validation Loss: 0.001146\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 82, Time Steps = 76, Early Stopping Patience = 8, Reduce LR Factor = 0.18, Reduce LR Patience = 5, Min LR = 0.000024\n",
      "X_train shape: (12599, 76, 5), X_test shape: (3150, 76, 5)\n",
      "Epoch 1/10\n",
      "154/154 [==============================] - 5s 12ms/step - loss: 1.1585 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 9.6357e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 8.5041e-04 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 7.3103e-04 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 6.9740e-04 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 6.8192e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 5.9912e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 5.4946e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Validation Loss: 0.001066\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 253, Batch Size = 77, Time Steps = 93, Early Stopping Patience = 9, Reduce LR Factor = 0.14, Reduce LR Patience = 6, Min LR = 0.000037\n",
      "X_train shape: (12585, 93, 5), X_test shape: (3147, 93, 5)\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 6s 17ms/step - loss: 1.0832 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 0.0022 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 9.8970e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 9.2440e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 7.5818e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 7.1265e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 6.4442e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 6.6091e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 2s 12ms/step - loss: 6.2286e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Validation Loss: 0.001325\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 95, Time Steps = 81, Early Stopping Patience = 11, Reduce LR Factor = 0.15, Reduce LR Patience = 6, Min LR = 0.000027\n",
      "X_train shape: (12595, 81, 5), X_test shape: (3149, 81, 5)\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 5s 14ms/step - loss: 1.3389 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 8.5446e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 7.6768e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 6.6304e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 6.0703e-04 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 6.1041e-04 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 1s 9ms/step - loss: 5.3771e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Validation Loss: 0.001032\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 256, Batch Size = 69, Time Steps = 79, Early Stopping Patience = 6, Reduce LR Factor = 0.15, Reduce LR Patience = 5, Min LR = 0.000022\n",
      "X_train shape: (12596, 79, 5), X_test shape: (3150, 79, 5)\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 5s 12ms/step - loss: 0.9750 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 0.0020 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 8.6367e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 7.4372e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 7.0552e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 6.4238e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 5.1967e-04 - val_loss: 0.0013 - lr: 1.5482e-04\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 5.0229e-04 - val_loss: 0.0011 - lr: 1.5482e-04\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 4.9267e-04 - val_loss: 0.0013 - lr: 1.5482e-04\n",
      "Validation Loss: 0.001087\n",
      "Best after iteration 7: [2.56000000e+02 7.77298732e+01 8.28155595e+01 6.78155526e+00\n",
      " 1.79428133e-01 5.27322867e+00 3.00288903e-05] 0.0009454936371184886\n",
      "Stopping search: maximum iterations reached --> 7\n",
      "\n",
      "Best Hyperparameters: LSTM Units = 256, Batch Size = 77, Time Steps = 82, Early Stopping Patience = 6, Reduce LR Factor = 0.18, Reduce LR Patience = 5, Min LR = 0.000030\n",
      "Best Validation Loss = 0.000945\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pyswarm\n",
    "from pyswarm import pso\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "param_ranges = {\n",
    "    \"lstm_units\": (32, 256),           # Range for LSTM units\n",
    "    \"batch_size\": (16, 128),           # Range for batch size\n",
    "    \"time_steps\": (30, 120),           # Range for sequence length\n",
    "    \"early_stopping_patience\": (5, 20),  # Range for early stopping patience\n",
    "    \"reduce_lr_factor\": (0.1, 0.5),      # Range for reduce_lr factor\n",
    "    \"reduce_lr_patience\": (2, 10),       # Range for reduce_lr patience\n",
    "    \"reduce_lr_min_lr\": (1e-6, 1e-4)     # Range for minimum learning rate\n",
    "}\n",
    "\n",
    "bounds = [\n",
    "    param_ranges[\"lstm_units\"],            # Bounds for LSTM units\n",
    "    param_ranges[\"batch_size\"],            # Bounds for batch size\n",
    "    param_ranges[\"time_steps\"],            # Bounds for sequence length\n",
    "    param_ranges[\"early_stopping_patience\"],  # Bounds for early stopping patience\n",
    "    param_ranges[\"reduce_lr_factor\"],         # Bounds for reduce_lr factor\n",
    "    param_ranges[\"reduce_lr_patience\"],       # Bounds for reduce_lr patience\n",
    "    param_ranges[\"reduce_lr_min_lr\"]          # Bounds for reduce_lr min_lr\n",
    "]\n",
    "\n",
    "def objective_function(params):\n",
    "    lstm_units = int(params[0])\n",
    "    batch_size = int(params[1])\n",
    "    time_steps = int(params[2])\n",
    "    early_stopping_patience = int(params[3])\n",
    "    reduce_lr_factor = float(params[4])\n",
    "    reduce_lr_patience = int(params[5])\n",
    "    reduce_lr_min_lr = float(params[6])\n",
    "    \n",
    "    print(f\"\\nTrying Hyperparameters: LSTM Units = {lstm_units}, Batch Size = {batch_size}, \"\n",
    "          f\"Time Steps = {time_steps}, Early Stopping Patience = {early_stopping_patience}, \"\n",
    "          f\"Reduce LR Factor = {reduce_lr_factor:.2f}, Reduce LR Patience = {reduce_lr_patience}, \"\n",
    "          f\"Min LR = {reduce_lr_min_lr:.6f}\")\n",
    "\n",
    "    # Updating sequence length for data creation\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    X, y = create_dataset(model_scaled_features, model_scaled_target, time_steps)\n",
    "    train_size = int(0.80 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Converting to tensors\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "    \n",
    "    input_shape = (time_steps, X_train.shape[2])\n",
    "    print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "\n",
    "    # Defining the new model architecture\n",
    "    model = Sequential([\n",
    "        # First LSTM layer with regularization\n",
    "        LSTM(lstm_units, return_sequences=True,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01),\n",
    "             input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Second LSTM layer\n",
    "        LSTM(lstm_units, return_sequences=False,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Output layer\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=early_stopping_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=reduce_lr_factor,\n",
    "        patience=reduce_lr_patience,\n",
    "        min_lr=reduce_lr_min_lr\n",
    "    )\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        X_train_tensor, y_train_tensor,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_tensor, y_test_tensor),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Getting validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Running PSO with the new model\n",
    "best_params, best_loss = pso(\n",
    "    objective_function,\n",
    "    lb=[b[0] for b in bounds],  # Lower bounds\n",
    "    ub=[b[1] for b in bounds],  # Upper bounds\n",
    "    swarmsize=7,               # Number of particles\n",
    "    maxiter=7,                 # Number of iterations\n",
    "    debug=True                  # Enable logging\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: LSTM Units = {int(best_params[0])}, Batch Size = {int(best_params[1])}, \"\n",
    "      f\"Time Steps = {int(best_params[2])}, Early Stopping Patience = {int(best_params[3])}, \"\n",
    "      f\"Reduce LR Factor = {best_params[4]:.2f}, Reduce LR Patience = {int(best_params[5])}, \"\n",
    "      f\"Min LR = {best_params[6]:.6f}\")\n",
    "print(f\"Best Validation Loss = {best_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96661738-1902-4d60-8938-9764a0f23fd3",
   "metadata": {},
   "source": [
    "### PSO (4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241dba9-e98d-4344-a8d4-5dcd7881d7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d8ff547-7bba-41f1-aecd-bceb07e12ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 177, Batch Size = 115, Time Steps = 95, Early Stopping Patience = 6, Reduce LR Factor = 0.33, Reduce LR Patience = 7, Min LR = 0.000054\n",
      "X_train shape: (12584, 95, 5), X_test shape: (3146, 95, 5)\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 5s 20ms/step - loss: 1.3624 - val_loss: 0.0400 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0095 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0020 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 8.7710e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 7.5937e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 7.2215e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 6.4140e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 6.3120e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Validation Loss: 0.001307\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 158, Batch Size = 16, Time Steps = 38, Early Stopping Patience = 6, Reduce LR Factor = 0.16, Reduce LR Patience = 4, Min LR = 0.000039\n",
      "X_train shape: (12629, 38, 5), X_test shape: (3158, 38, 5)\n",
      "Epoch 1/10\n",
      "790/790 [==============================] - 7s 5ms/step - loss: 0.1840 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 0.0010 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 9.1027e-04 - val_loss: 0.0108 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 7.5319e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 7.1936e-04 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 6.9793e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 4.9132e-04 - val_loss: 0.0027 - lr: 1.5895e-04\n",
      "Epoch 8/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 4.7724e-04 - val_loss: 0.0014 - lr: 1.5895e-04\n",
      "Epoch 9/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 4.5972e-04 - val_loss: 0.0024 - lr: 1.5895e-04\n",
      "Epoch 10/10\n",
      "790/790 [==============================] - 4s 5ms/step - loss: 4.6706e-04 - val_loss: 0.0015 - lr: 1.5895e-04\n",
      "Validation Loss: 0.001408\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 187, Batch Size = 73, Time Steps = 104, Early Stopping Patience = 10, Reduce LR Factor = 0.23, Reduce LR Patience = 7, Min LR = 0.000071\n",
      "X_train shape: (12576, 104, 5), X_test shape: (3145, 104, 5)\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 6s 16ms/step - loss: 0.8942 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 0.0024 - val_loss: 0.0069 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 2s 12ms/step - loss: 0.0012 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 9.4462e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 2s 12ms/step - loss: 8.0475e-04 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 7.2334e-04 - val_loss: 0.0035 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 2s 12ms/step - loss: 6.6913e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 2s 12ms/step - loss: 6.1065e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 2s 12ms/step - loss: 5.9032e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 5.9350e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Validation Loss: 0.001123\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 231, Batch Size = 20, Time Steps = 66, Early Stopping Patience = 10, Reduce LR Factor = 0.36, Reduce LR Patience = 3, Min LR = 0.000004\n",
      "X_train shape: (12607, 66, 5), X_test shape: (3152, 66, 5)\n",
      "Epoch 1/10\n",
      "631/631 [==============================] - 8s 8ms/step - loss: 0.2698 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 8.8554e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 7.4230e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 7.1972e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 6.8748e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 4.9437e-04 - val_loss: 0.0012 - lr: 3.5860e-04\n",
      "Epoch 8/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 4.8300e-04 - val_loss: 0.0015 - lr: 3.5860e-04\n",
      "Epoch 9/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 4.8422e-04 - val_loss: 0.0023 - lr: 3.5860e-04\n",
      "Epoch 10/10\n",
      "631/631 [==============================] - 5s 7ms/step - loss: 4.0011e-04 - val_loss: 0.0014 - lr: 1.2859e-04\n",
      "Validation Loss: 0.001093\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 228, Batch Size = 111, Time Steps = 103, Early Stopping Patience = 10, Reduce LR Factor = 0.20, Reduce LR Patience = 7, Min LR = 0.000096\n",
      "X_train shape: (12577, 103, 5), X_test shape: (3145, 103, 5)\n",
      "Epoch 1/10\n",
      "114/114 [==============================] - 5s 20ms/step - loss: 1.4830 - val_loss: 0.0216 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0055 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0012 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 9.5620e-04 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 8.4775e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 7.9632e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 6.9266e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 6.1310e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 6.5706e-04 - val_loss: 0.0060 - lr: 0.0010\n",
      "Validation Loss: 0.001683\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 91, Batch Size = 37, Time Steps = 70, Early Stopping Patience = 5, Reduce LR Factor = 0.10, Reduce LR Patience = 2, Min LR = 0.000027\n",
      "X_train shape: (12604, 70, 5), X_test shape: (3151, 70, 5)\n",
      "Epoch 1/10\n",
      "341/341 [==============================] - 6s 9ms/step - loss: 0.3283 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.0014 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 9.4812e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 8.1619e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 7.3980e-04 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 6.5741e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 6.0452e-04 - val_loss: 0.0026 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 6.1706e-04 - val_loss: 0.0043 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 4.8016e-04 - val_loss: 0.0017 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 4.6760e-04 - val_loss: 0.0016 - lr: 1.0000e-04\n",
      "Validation Loss: 0.001308\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 221, Batch Size = 70, Time Steps = 120, Early Stopping Patience = 5, Reduce LR Factor = 0.40, Reduce LR Patience = 2, Min LR = 0.000021\n",
      "X_train shape: (12564, 120, 5), X_test shape: (3141, 120, 5)\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 7s 19ms/step - loss: 0.9270 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.0021 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 9.5582e-04 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 7.5386e-04 - val_loss: 0.0032 - lr: 4.0409e-04\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 6.9873e-04 - val_loss: 0.0016 - lr: 4.0409e-04\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 6.6681e-04 - val_loss: 0.0022 - lr: 4.0409e-04\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 6.2178e-04 - val_loss: 0.0017 - lr: 4.0409e-04\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 5.7922e-04 - val_loss: 0.0014 - lr: 1.6329e-04\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 5.5750e-04 - val_loss: 0.0014 - lr: 1.6329e-04\n",
      "Validation Loss: 0.001390\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 141, Batch Size = 24, Time Steps = 84, Early Stopping Patience = 5, Reduce LR Factor = 0.50, Reduce LR Patience = 4, Min LR = 0.000001\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 8s 9ms/step - loss: 0.2608 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 0.0011 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 8.8246e-04 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 7.3749e-04 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 7.3669e-04 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 6.6676e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 6.8740e-04 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 5.1215e-04 - val_loss: 0.0030 - lr: 5.0000e-04\n",
      "Validation Loss: 0.001741\n",
      "Best after iteration 1: [2.31622966e+02 2.05801786e+01 6.62646936e+01 1.01708046e+01\n",
      " 3.58595462e-01 3.77597748e+00 3.85024478e-06] 0.0010928313713520765\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 230, Batch Size = 80, Time Steps = 101, Early Stopping Patience = 10, Reduce LR Factor = 0.23, Reduce LR Patience = 7, Min LR = 0.000068\n",
      "X_train shape: (12579, 101, 5), X_test shape: (3145, 101, 5)\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 6s 19ms/step - loss: 1.0777 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 0.0025 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 0.0013 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 9.4587e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 8.1678e-04 - val_loss: 0.0067 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 7.6417e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 6.7424e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 6.6772e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 6.0301e-04 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 6.3441e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Validation Loss: 0.001275\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 116, Batch Size = 43, Time Steps = 84, Early Stopping Patience = 5, Reduce LR Factor = 0.13, Reduce LR Patience = 2, Min LR = 0.000016\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "293/293 [==============================] - 6s 9ms/step - loss: 0.4234 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 0.0015 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 9.4614e-04 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 7.8204e-04 - val_loss: 0.0020 - lr: 1.2578e-04\n",
      "Epoch 5/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 7.2971e-04 - val_loss: 0.0020 - lr: 1.2578e-04\n",
      "Epoch 6/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 7.2262e-04 - val_loss: 0.0022 - lr: 1.2578e-04\n",
      "Epoch 7/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 6.9382e-04 - val_loss: 0.0021 - lr: 1.6007e-05\n",
      "Epoch 8/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 6.9061e-04 - val_loss: 0.0023 - lr: 1.6007e-05\n",
      "Epoch 9/10\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 6.8020e-04 - val_loss: 0.0021 - lr: 1.6007e-05\n",
      "Validation Loss: 0.001983\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 238, Batch Size = 65, Time Steps = 104, Early Stopping Patience = 5, Reduce LR Factor = 0.46, Reduce LR Patience = 2, Min LR = 0.000014\n",
      "X_train shape: (12576, 104, 5), X_test shape: (3145, 104, 5)\n",
      "Epoch 1/10\n",
      "194/194 [==============================] - 6s 17ms/step - loss: 0.8911 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 0.0019 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 0.0012 - val_loss: 0.0023 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 8.6810e-04 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 7.5260e-04 - val_loss: 0.0041 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 7.1388e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 6.5107e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 6.4022e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 5.4017e-04 - val_loss: 0.0011 - lr: 4.6106e-04\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 3s 13ms/step - loss: 5.1034e-04 - val_loss: 0.0011 - lr: 4.6106e-04\n",
      "Validation Loss: 0.001107\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 139, Batch Size = 25, Time Steps = 84, Early Stopping Patience = 7, Reduce LR Factor = 0.50, Reduce LR Patience = 4, Min LR = 0.000001\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "504/504 [==============================] - 8s 9ms/step - loss: 0.2673 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 0.0010 - val_loss: 0.0028 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 8.4584e-04 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 7.3153e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 6.6997e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 6.2295e-04 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 6.2733e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 5.8977e-04 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 5.9051e-04 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 4.8543e-04 - val_loss: 0.0026 - lr: 5.0000e-04\n",
      "Validation Loss: 0.001130\n",
      "Best after iteration 2: [2.31622966e+02 2.05801786e+01 6.62646936e+01 1.01708046e+01\n",
      " 3.58595462e-01 3.77597748e+00 3.85024478e-06] 0.0010928313713520765\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 232, Batch Size = 38, Time Steps = 98, Early Stopping Patience = 11, Reduce LR Factor = 0.26, Reduce LR Patience = 5, Min LR = 0.000046\n",
      "X_train shape: (12581, 98, 5), X_test shape: (3146, 98, 5)\n",
      "Epoch 1/10\n",
      "332/332 [==============================] - 7s 10ms/step - loss: 0.5144 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 0.0013 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 9.1301e-04 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 7.7261e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 6.9235e-04 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 6.5559e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 6.4398e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 6.2229e-04 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 5.5619e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "332/332 [==============================] - 3s 8ms/step - loss: 6.3944e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Validation Loss: 0.001079\n",
      "New best for swarm at iteration 3: [2.32369311e+02 3.84213612e+01 9.82992027e+01 1.10687339e+01\n",
      " 2.61853071e-01 5.51574002e+00 4.60559626e-05] 0.001078586676158011\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 140, Batch Size = 44, Time Steps = 90, Early Stopping Patience = 7, Reduce LR Factor = 0.13, Reduce LR Patience = 2, Min LR = 0.000026\n",
      "X_train shape: (12588, 90, 5), X_test shape: (3147, 90, 5)\n",
      "Epoch 1/10\n",
      "287/287 [==============================] - 6s 10ms/step - loss: 0.4718 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 0.0015 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 9.8750e-04 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 7.6951e-04 - val_loss: 0.0020 - lr: 1.3499e-04\n",
      "Epoch 5/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 7.3887e-04 - val_loss: 0.0030 - lr: 1.3499e-04\n",
      "Epoch 6/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 7.1378e-04 - val_loss: 0.0026 - lr: 1.3499e-04\n",
      "Epoch 7/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 6.8691e-04 - val_loss: 0.0024 - lr: 2.6269e-05\n",
      "Epoch 8/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 6.8820e-04 - val_loss: 0.0024 - lr: 2.6269e-05\n",
      "Epoch 9/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 6.8724e-04 - val_loss: 0.0025 - lr: 2.6269e-05\n",
      "Epoch 10/10\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 6.8391e-04 - val_loss: 0.0018 - lr: 2.6269e-05\n",
      "Validation Loss: 0.001848\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 245, Batch Size = 52, Time Steps = 95, Early Stopping Patience = 7, Reduce LR Factor = 0.49, Reduce LR Patience = 2, Min LR = 0.000022\n",
      "X_train shape: (12584, 95, 5), X_test shape: (3146, 95, 5)\n",
      "Epoch 1/10\n",
      "242/242 [==============================] - 6s 14ms/step - loss: 0.7218 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.0015 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.0010 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 8.0560e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 7.2648e-04 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 6.1600e-04 - val_loss: 0.0012 - lr: 4.8555e-04\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 5.8517e-04 - val_loss: 0.0035 - lr: 4.8555e-04\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 5.3947e-04 - val_loss: 0.0011 - lr: 4.8555e-04\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 4.9645e-04 - val_loss: 0.0013 - lr: 2.3576e-04\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 4.9332e-04 - val_loss: 0.0019 - lr: 2.3576e-04\n",
      "Validation Loss: 0.001097\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 184, Batch Size = 26, Time Steps = 84, Early Stopping Patience = 9, Reduce LR Factor = 0.44, Reduce LR Patience = 4, Min LR = 0.000013\n",
      "X_train shape: (12592, 84, 5), X_test shape: (3149, 84, 5)\n",
      "Epoch 1/10\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3164 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.0011 - val_loss: 0.0017 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 8.3063e-04 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 8.3577e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 7.2036e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 6.4654e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 6.2006e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 6.3098e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 6.9549e-04 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 4.5064e-04 - val_loss: 0.0017 - lr: 4.3526e-04\n",
      "Validation Loss: 0.001170\n",
      "Best after iteration 3: [2.32369311e+02 3.84213612e+01 9.82992027e+01 1.10687339e+01\n",
      " 2.61853071e-01 5.51574002e+00 4.60559626e-05] 0.001078586676158011\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 233, Batch Size = 17, Time Steps = 96, Early Stopping Patience = 11, Reduce LR Factor = 0.28, Reduce LR Patience = 4, Min LR = 0.000035\n",
      "X_train shape: (12583, 96, 5), X_test shape: (3146, 96, 5)\n",
      "Epoch 1/10\n",
      "741/741 [==============================] - 11s 11ms/step - loss: 0.2327 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 0.0011 - val_loss: 0.0024 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 8.7541e-04 - val_loss: 0.0014 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 7.8945e-04 - val_loss: 0.0019 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 7.6366e-04 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 6.9823e-04 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 7.2661e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 5.1288e-04 - val_loss: 0.0028 - lr: 2.7612e-04\n",
      "Epoch 9/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 4.8288e-04 - val_loss: 0.0032 - lr: 2.7612e-04\n",
      "Epoch 10/10\n",
      "741/741 [==============================] - 7s 10ms/step - loss: 4.8593e-04 - val_loss: 0.0014 - lr: 2.7612e-04\n",
      "Validation Loss: 0.001358\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 154, Batch Size = 41, Time Steps = 85, Early Stopping Patience = 9, Reduce LR Factor = 0.17, Reduce LR Patience = 4, Min LR = 0.000032\n",
      "X_train shape: (12592, 85, 5), X_test shape: (3148, 85, 5)\n",
      "Epoch 1/10\n",
      "308/308 [==============================] - 6s 10ms/step - loss: 0.4615 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 0.0014 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 9.9597e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 8.1661e-04 - val_loss: 0.0027 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 7.2222e-04 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 6.7649e-04 - val_loss: 0.0022 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 6.5281e-04 - val_loss: 0.0042 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "308/308 [==============================] - 3s 9ms/step - loss: 5.2289e-04 - val_loss: 0.0022 - lr: 1.7334e-04\n",
      "Epoch 9/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 4.9990e-04 - val_loss: 0.0025 - lr: 1.7334e-04\n",
      "Epoch 10/10\n",
      "308/308 [==============================] - 3s 8ms/step - loss: 5.1026e-04 - val_loss: 0.0015 - lr: 1.7334e-04\n",
      "Validation Loss: 0.001544\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 246, Batch Size = 40, Time Steps = 91, Early Stopping Patience = 9, Reduce LR Factor = 0.47, Reduce LR Patience = 2, Min LR = 0.000029\n",
      "X_train shape: (12587, 91, 5), X_test shape: (3147, 91, 5)\n",
      "Epoch 1/10\n",
      "315/315 [==============================] - 7s 12ms/step - loss: 0.5576 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 0.0012 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 9.4229e-04 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 7.5998e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 6.9616e-04 - val_loss: 0.0018 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 6.8119e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 5.3571e-04 - val_loss: 0.0025 - lr: 4.7480e-04\n",
      "Epoch 8/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 5.0022e-04 - val_loss: 0.0022 - lr: 4.7480e-04\n",
      "Epoch 9/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 4.5944e-04 - val_loss: 0.0012 - lr: 2.2544e-04\n",
      "Epoch 10/10\n",
      "315/315 [==============================] - 3s 10ms/step - loss: 4.6207e-04 - val_loss: 0.0012 - lr: 2.2544e-04\n",
      "Validation Loss: 0.001151\n",
      "\n",
      "Trying Hyperparameters: LSTM Units = 225, Batch Size = 30, Time Steps = 83, Early Stopping Patience = 10, Reduce LR Factor = 0.31, Reduce LR Patience = 5, Min LR = 0.000021\n",
      "X_train shape: (12593, 83, 5), X_test shape: (3149, 83, 5)\n",
      "Epoch 1/10\n",
      "420/420 [==============================] - 7s 11ms/step - loss: 0.4012 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.0012 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 8.8533e-04 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 8.2537e-04 - val_loss: 0.0037 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 6.9722e-04 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 6.7780e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 6.5945e-04 - val_loss: 0.0020 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 5.7541e-04 - val_loss: 0.0025 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 6.1545e-04 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 6.3023e-04 - val_loss: 0.0031 - lr: 0.0010\n",
      "Validation Loss: 0.001223\n",
      "Best after iteration 4: [2.32369311e+02 3.84213612e+01 9.82992027e+01 1.10687339e+01\n",
      " 2.61853071e-01 5.51574002e+00 4.60559626e-05] 0.001078586676158011\n",
      "Stopping search: maximum iterations reached --> 4\n",
      "\n",
      "Best Hyperparameters: LSTM Units = 232, Batch Size = 38, Time Steps = 98, Early Stopping Patience = 11, Reduce LR Factor = 0.26, Reduce LR Patience = 5, Min LR = 0.000046\n",
      "Best Validation Loss = 0.001079\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pyswarm\n",
    "from pyswarm import pso\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "param_ranges = {\n",
    "    \"lstm_units\": (32, 256),           # Range for LSTM units\n",
    "    \"batch_size\": (16, 128),           # Range for batch size\n",
    "    \"time_steps\": (30, 120),           # Range for sequence length\n",
    "    \"early_stopping_patience\": (5, 20),  # Range for early stopping patience\n",
    "    \"reduce_lr_factor\": (0.1, 0.5),      # Range for reduce_lr factor\n",
    "    \"reduce_lr_patience\": (2, 10),       # Range for reduce_lr patience\n",
    "    \"reduce_lr_min_lr\": (1e-6, 1e-4)     # Range for minimum learning rate\n",
    "}\n",
    "\n",
    "bounds = [\n",
    "    param_ranges[\"lstm_units\"],            # Bounds for LSTM units\n",
    "    param_ranges[\"batch_size\"],            # Bounds for batch size\n",
    "    param_ranges[\"time_steps\"],            # Bounds for sequence length\n",
    "    param_ranges[\"early_stopping_patience\"],  # Bounds for early stopping patience\n",
    "    param_ranges[\"reduce_lr_factor\"],         # Bounds for reduce_lr factor\n",
    "    param_ranges[\"reduce_lr_patience\"],       # Bounds for reduce_lr patience\n",
    "    param_ranges[\"reduce_lr_min_lr\"]          # Bounds for reduce_lr min_lr\n",
    "]\n",
    "\n",
    "def objective_function(params):\n",
    "    lstm_units = int(params[0])\n",
    "    batch_size = int(params[1])\n",
    "    time_steps = int(params[2])\n",
    "    early_stopping_patience = int(params[3])\n",
    "    reduce_lr_factor = float(params[4])\n",
    "    reduce_lr_patience = int(params[5])\n",
    "    reduce_lr_min_lr = float(params[6])\n",
    "    \n",
    "    print(f\"\\nTrying Hyperparameters: LSTM Units = {lstm_units}, Batch Size = {batch_size}, \"\n",
    "          f\"Time Steps = {time_steps}, Early Stopping Patience = {early_stopping_patience}, \"\n",
    "          f\"Reduce LR Factor = {reduce_lr_factor:.2f}, Reduce LR Patience = {reduce_lr_patience}, \"\n",
    "          f\"Min LR = {reduce_lr_min_lr:.6f}\")\n",
    "\n",
    "    # Updating sequence length for data creation\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    X, y = create_dataset(model_scaled_features, model_scaled_target, time_steps)\n",
    "    train_size = int(0.80 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Converting to tensors\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "    y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "    X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "    \n",
    "    input_shape = (time_steps, X_train.shape[2])\n",
    "    print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "\n",
    "    # Defining the new model architecture\n",
    "    model = Sequential([\n",
    "        # First LSTM layer with regularization\n",
    "        LSTM(lstm_units, return_sequences=True,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01),\n",
    "             input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Second LSTM layer\n",
    "        LSTM(lstm_units, return_sequences=False,\n",
    "             kernel_regularizer=l2(0.01),\n",
    "             recurrent_regularizer=l2(0.01)),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        # Output layer\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=early_stopping_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=reduce_lr_factor,\n",
    "        patience=reduce_lr_patience,\n",
    "        min_lr=reduce_lr_min_lr\n",
    "    )\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        X_train_tensor, y_train_tensor,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_tensor, y_test_tensor),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Getting validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Running PSO with the new model\n",
    "best_params, best_loss = pso(\n",
    "    objective_function,\n",
    "    lb=[b[0] for b in bounds],  # Lower bounds\n",
    "    ub=[b[1] for b in bounds],  # Upper bounds\n",
    "    swarmsize=4,               # Number of particles\n",
    "    maxiter=4,                 # Number of iterations\n",
    "    debug=True                  # Enable logging\n",
    ")\n",
    "\n",
    "print(f\"\\nBest Hyperparameters: LSTM Units = {int(best_params[0])}, Batch Size = {int(best_params[1])}, \"\n",
    "      f\"Time Steps = {int(best_params[2])}, Early Stopping Patience = {int(best_params[3])}, \"\n",
    "      f\"Reduce LR Factor = {best_params[4]:.2f}, Reduce LR Patience = {int(best_params[5])}, \"\n",
    "      f\"Min LR = {best_params[6]:.6f}\")\n",
    "print(f\"Best Validation Loss = {best_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b649b5-8a99-45f3-8977-cc0d8030ee83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb3781-e5e5-40be-b82b-50938b2e6e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4-TensorFlow-2.11.0-cuda [jupyter_python]",
   "language": "python",
   "name": "sys_python_3.10.4-tensorflow-2.11.0-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
